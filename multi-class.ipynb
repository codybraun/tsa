{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: dask in /usr/local/lib/python3.5/site-packages\n",
      "Requirement already satisfied: objgraph in /usr/local/lib/python3.5/site-packages\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.5/site-packages (from objgraph)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "import tsa_utils\n",
    "\n",
    "from shutil import copytree\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "import pip\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "pip.main(['install', '--upgrade', 'dask'])\n",
    "pip.main(['install', 'objgraph'])\n",
    "\n",
    "import objgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copytree(\"/models/multi-class8/multi_class\", \"/output/multi_class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model parameters\n",
    "BATCH_SIZE=10\n",
    "FILTER_COUNT=5\n",
    "KERNEL_SIZE1=(1,5,5)\n",
    "DEPTHSTRIDE=1\n",
    "XSTRIDE=1\n",
    "YSTRIDE=1\n",
    "POOLSIZE1=(1,3,3)\n",
    "POOLSIZE2=(1,5,5)\n",
    "POOL_STRIDES1=(1,2,2)\n",
    "POOL_STRIDES=(1,1,1)\n",
    "STEPS=1600\n",
    "XSIZE=256\n",
    "#XSIZE=512\n",
    "#XSIZE=270\n",
    "#YSIZE=340\n",
    "YSIZE=330\n",
    "#YSIZE=660\n",
    "LEARNING_RATE=0.0001\n",
    "EPSILON=0\n",
    "IMAGE_DEPTH=64\n",
    "CHANNELS=1\n",
    "FLAT_POOL_SIZE=2992000\n",
    "REGULARIZER_VALUE=0.1\n",
    "\n",
    "DATA_PATH=\"/a3d_volume/\"\n",
    "CHECKPOINT_PATH=\"/output/multi_class\"\n",
    "MODEL_ID=\"multi_class3d3\"\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ZoneModel():\n",
    "\n",
    "    def __init__(self, model_id, ids, x_slice, y_slice, data_path, labels, checkpoint_path=\".\", localize=False,scaler_ids=None, iteratorClass=tsa_utils.InputImagesIterator, test_ids=None, test_labels=None):\n",
    "        self.model_id = model_id\n",
    "        self.ids = ids\n",
    "        self.x_slice = x_slice\n",
    "        self.y_slice = y_slice\n",
    "        self.data_path = data_path\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.labels = labels\n",
    "        self.localize = localize\n",
    "        self.scaler_ids=scaler_ids\n",
    "        self.iteratorClass = iteratorClass\n",
    "        self.test_ids = test_ids\n",
    "        self.test_labels = test_labels\n",
    "        \n",
    "\n",
    "    def build_model(self, data, labels, mode):\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(REGULARIZER_VALUE)\n",
    "        print(regularizer)\n",
    "        if mode != tf.contrib.learn.ModeKeys.TRAIN:\n",
    "            BATCH_SIZE=1\n",
    "        else:\n",
    "            BATCH_SIZE=10\n",
    "            \n",
    "        training = (mode==tf.contrib.learn.ModeKeys.TRAIN)\n",
    "        print(training)\n",
    "        print(XSIZE, YSIZE)\n",
    "        data = tf.reshape(data, [BATCH_SIZE, IMAGE_DEPTH, YSIZE, XSIZE, CHANNELS])\n",
    "        normalizer = tf.contrib.layers.batch_norm(\n",
    "            data,\n",
    "            data_format='NHWC',  # Matching the \"cnn\" tensor which has shape (?, 9, 120, 160, 96).\n",
    "            center=True,\n",
    "            scale=True,\n",
    "            is_training=training,\n",
    "            scope='cnn3d-batch_norm')\n",
    "\n",
    "        dropout = tf.layers.dropout(normalizer, rate=0.3, training=training)\n",
    "        conv1 = tf.layers.conv3d(inputs=dropout, filters=FILTER_COUNT, kernel_size=KERNEL_SIZE1, padding=\"same\", \n",
    "                strides=(DEPTHSTRIDE,XSTRIDE,YSTRIDE), name=\"conv1\", trainable=not self.localize, kernel_regularizer=regularizer, bias_regularizer=regularizer)\n",
    "        print(conv1)\n",
    "#         pool0 = tf.layers.max_pooling3d(inputs=conv1, pool_size=POOLSIZE1, strides=POOL_STRIDES1, name=\"pool0\")\n",
    "#         print(pool0)\n",
    "#         conv2 = tf.layers.conv3d(inputs=conv1, filters=FILTER_COUNT, kernel_size=(1,3,3), padding=\"same\",\n",
    "#                 strides=(1, 2, 2), name=\"conv2\", activation=tf.nn.relu, trainable=not self.localize, kernel_regularizer=regularizer)\n",
    "#         print(conv2)\n",
    "#         pool1 = tf.layers.max_pooling3d(inputs=conv2, pool_size=POOLSIZE1, strides=POOL_STRIDES1, name=\"pool1\")\n",
    "#         print(pool1)\n",
    "#         conv3 = tf.layers.conv3d(inputs=pool1, filters=FILTER_COUNT, kernel_size=(1,3,3), padding=\"same\", \n",
    "#                 strides=(DEPTHSTRIDE,2,2), name=\"conv3\", trainable=not self.localize, kernel_regularizer=regularizer)\n",
    "#         print(conv3)\n",
    "        pool2 = tf.layers.max_pooling3d(inputs=conv1, pool_size=(1,3,3), strides=(1,3,3), name=\"pool2\")\n",
    "        print(pool2)\n",
    "        conv4 = tf.layers.conv3d(inputs=pool2, filters=FILTER_COUNT, kernel_size=(1,3,3), padding=\"same\", \n",
    "                strides=(1, 1, 1), name=\"conv4\", activation=tf.nn.relu, trainable=not self.localize, kernel_regularizer=regularizer, bias_regularizer=regularizer)\n",
    "        print(conv4)\n",
    "        flat_pool = tf.reshape(conv4, [BATCH_SIZE, FLAT_POOL_SIZE])\n",
    "        flat_pool=tf.identity(flat_pool, name=\"flat_pool\")\n",
    "        print(flat_pool)\n",
    "#         dense = tf.layers.dense(inputs=flat_pool, units=100, trainable=True, activation=tf.nn.relu)\n",
    "#         print(dense)\n",
    "        dropout2 = tf.layers.dropout(flat_pool, rate=0.3, training=training)\n",
    "        print(dropout2)\n",
    "        logits = tf.layers.dense(inputs=dropout2, units=17, trainable=True, kernel_regularizer=regularizer, bias_regularizer=regularizer)\n",
    "        logits = tf.identity(logits, name=\"logits\")\n",
    "        logits = tf.reshape(logits, [BATCH_SIZE,17])\n",
    "        reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        reg_losses = tf.identity(reg_losses, \"reg_losses\")\n",
    "        predictions = {\n",
    "            \"classes\": tf.argmax(\n",
    "              input=logits, axis=1, name=\"classes\"),\n",
    "          \"probabilities\": tf.nn.sigmoid(\n",
    "              logits, name=\"prob_tensor\")}\n",
    "        print(mode)\n",
    "        if mode == tf.contrib.learn.ModeKeys.INFER:\n",
    "            return tf.contrib.learn.ModelFnOps(mode=mode, predictions=predictions)\n",
    "        #flat_labels = tf.reshape(labels, [BATCH_SIZE, 17])\n",
    "        labels=tf.identity(labels, name=\"labels\")\n",
    "        labels = tf.cast(labels, tf.float32)\n",
    "        #class_weights=tf.reduce_sum(tf.multiply(flat_labels, tf.constant(WEIGHTS, dtype=tf.int64)), axis=1)\n",
    "        #print(class_weights)\n",
    "        #loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)\n",
    "        if mode == tf.contrib.learn.ModeKeys.TRAIN:\n",
    "            loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)) + sum(\n",
    "                    tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "        else:\n",
    "            print(\"RUNNGIN IN MODE \" + str(mode))\n",
    "            loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            optimizer=\"SGD\")\n",
    "\n",
    "        return tf.contrib.learn.ModelFnOps(mode=mode, predictions=predictions, loss=loss, train_op=train_op)\n",
    "\n",
    "    def train_model(self, tensors_to_log, reuse=False):\n",
    "        if reuse:\n",
    "            tsa_classifier = self.model\n",
    "        else:\n",
    "            tsa_classifier = tf.contrib.learn.Estimator(model_fn=self.build_model, \n",
    "                                                     model_dir=self.checkpoint_path + \"/\" + self.model_id)\n",
    "            \n",
    "#         validation_metrics = {\n",
    "#         \"accuracy\":\n",
    "#             tf.contrib.learn.MetricSpec(\n",
    "#                 metric_fn=tf.contrib.metrics.streaming_accuracy,\n",
    "#                 prediction_key=tf.cast(tf.reshape(tf.contrib.learn.PredictionKey.CLASSES,[1,1]), tf.bool).eval()),\n",
    "#         \"precision\":\n",
    "#             tf.contrib.learn.MetricSpec(\n",
    "#                 metric_fn=tf.contrib.metrics.streaming_precision,\n",
    "#                 prediction_key=tf.cast(tf.reshape(tf.contrib.learn.PredictionKey.CLASSES, [1,1]), tf.bool).eval()),\n",
    "#         \"recall\":\n",
    "#             tf.contrib.learn.MetricSpec(\n",
    "#                 metric_fn=tf.contrib.metrics.streaming_recall,\n",
    "#                 prediction_key=tf.cast(tf.reshape(tf.contrib.learn.PredictionKey.CLASSES, [1,1]), tf.bool).eval())\n",
    "#         }\n",
    "        \n",
    "#         validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "#             self.iteratorClass(self.test_ids, self.data_path, repeating=False, pool_size=2),\n",
    "#             tsa_utils.InputLabelsIterator(self.test_ids, self.test_labels),\n",
    "#             every_n_steps=100, early_stopping_rounds=300, metrics=validation_metrics)\n",
    "        \n",
    "        logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=100)\n",
    "        #f1_hook = calculate_f1(self.model)\n",
    "        tsa_classifier.fit(\n",
    "            #x=tsa_utils.ThresholdedInputImagesIterator(self.ids, self.data_path, 10000, self.y_slice, self.x_slice, pool_size=2), \n",
    "            x=self.iteratorClass(self.ids, self.data_path, repeating=True, pool_size=2, file_format=\".a3daps\"),\n",
    "            y=tsa_utils.InputLabelsIterator(self.ids, self.labels), \n",
    "            max_steps=STEPS, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            #monitors=[logging_hook, validation_monitor])\n",
    "            monitors=[logging_hook])\n",
    "\n",
    "        self.model = tsa_classifier\n",
    "\n",
    "    def load_model(self, checkpoint=None):\n",
    "        print(self.checkpoint_path, self.model_id)\n",
    "        if checkpoint:\n",
    "            tsa_classifier = tf.contrib.learn.Estimator(model_fn=self.build_model, \n",
    "                                                    model_dir=self.checkpoint_path + \"/\" + self.model_id + \"/model.ckpt-\" + str(checkpoint))\n",
    "        else:\n",
    "            tsa_classifier = tf.contrib.learn.Estimator(model_fn=self.build_model, \n",
    "                                                    model_dir=self.checkpoint_path + \"/\" + self.model_id)\n",
    "        print (\"LOADED MODEL AT STEP \" + str(tsa_classifier.get_variable_value(\"global_step\")) + \" FROM \" + self.checkpoint_path + \"/\" + self.model_id )\n",
    "        self.model = tsa_classifier\n",
    "\n",
    "    def bootstrap_model(self, path=None):\n",
    "        if path:\n",
    "            checkpoint_path = path\n",
    "        else:\n",
    "            checkpoint_path = self.checkpoint_path + \"/\" + self.model_id\n",
    "        print (\"USING CHECKPOINT PATH  \" + checkpoint_path)\n",
    "        tsa_classifier = tf.contrib.learn.Estimator(model_fn=self.build_model, \n",
    "                                                    model_dir=checkpoint_path)\n",
    "        print (\"BOOTSTRAPPED AT STEP \" + str(tsa_classifier.get_variable_value(\"global_step\")))\n",
    "        self.model = tsa_classifier \n",
    "\n",
    "    def predict(self):\n",
    "        return self.model.predict(x=self.iteratorClass(self.ids, self.data_path, repeating=False, pool_size=2, scaler_ids=self.scaler_ids, file_format=\".a3daps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/pandas/core/generic.py:3110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/usr/local/lib/python3.5/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "tensors_to_log =  {\"probabilities\": \"prob_tensor\",\n",
    "                    \"actual\":\"labels\",\"reg_losses\":\"reg_losses\"}\n",
    "\n",
    "image_df = pd.read_csv(DATA_PATH + '/stage1_labels.csv')\n",
    "image_df['zone'] = image_df['Id'].str.split(\"_Zone\", expand=True)[1].str.strip()\n",
    "image_df['id'] = image_df['Id'].str.split(\"_\", expand=True)[0].str.strip()\n",
    "\n",
    "ids = image_df[\"id\"].unique()\n",
    "ids.sort()\n",
    "train_ids, test_ids, _, _ = train_test_split(ids, ids, test_size=.1)\n",
    "train_ids.sort()\n",
    "test_ids.sort()\n",
    "\n",
    "\n",
    "train_labels = image_df[image_df['id'].isin(train_ids)]\n",
    "train_labels.zone = train_labels.zone.astype(\"int\")\n",
    "train_labels = train_labels.sort_values([\"id\",\"zone\"])\n",
    "train_labels = train_labels[\"Probability\"]\n",
    "train_labels = np.reshape(train_labels, (-1,17))\n",
    "\n",
    "test_labels = image_df[image_df['id'].isin(test_ids)]\n",
    "test_labels.zone = test_labels.zone.astype(\"int\")\n",
    "test_labels = test_labels.sort_values([\"id\",\"zone\"])\n",
    "test_labels = test_labels[\"Probability\"]\n",
    "# test_labels = np.reshape(test_labels, (-1,17))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('./stage1_sample_submission.csv')\n",
    "eval_df['zone'] = eval_df['Id'].str.split(\"_\", expand=True)[1].str.strip()\n",
    "eval_df['id'] = eval_df['Id'].str.split(\"_\", expand=True)[0].str.strip()\n",
    "\n",
    "eval_ids = eval_df[\"id\"].unique()\n",
    "eval_ids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "Using default config.\n",
      "INFO:tensorflow:Using config: {'_num_worker_replicas': 0, '_environment': 'local', '_save_checkpoints_secs': 600, '_task_type': None, '_task_id': 0, '_save_checkpoints_steps': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7a383fb278>, '_save_summary_steps': 100, '_session_config': None, '_tf_random_seed': None, '_model_dir': '/output/multi_class/multi_class3d3', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_master': '', '_is_chief': True, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': ''}\n",
      "Using config: {'_num_worker_replicas': 0, '_environment': 'local', '_save_checkpoints_secs': 600, '_task_type': None, '_task_id': 0, '_save_checkpoints_steps': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7a383fb278>, '_save_summary_steps': 100, '_session_config': None, '_tf_random_seed': None, '_model_dir': '/output/multi_class/multi_class3d3', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_master': '', '_is_chief': True, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': ''}\n",
      "WARNING:tensorflow:From <ipython-input-46-01cea8e8e477>:133: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From <ipython-input-46-01cea8e8e477>:133: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-46-01cea8e8e477>:133: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From <ipython-input-46-01cea8e8e477>:133: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-46-01cea8e8e477>:133: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From <ipython-input-46-01cea8e8e477>:133: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function l2_regularizer.<locals>.l2 at 0x7f7a55eadd90>\n",
      "True\n",
      "256 330\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 64, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 64, 110, 85, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 64, 110, 85, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 2992000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 2992000), dtype=float32)\n",
      "train\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /output/multi_class/multi_class3d3/model.ckpt-1\n",
      "Restoring parameters from /output/multi_class/multi_class3d3/model.ckpt-1\n",
      "INFO:tensorflow:Saving checkpoints for 2 into /output/multi_class/multi_class3d3/model.ckpt.\n",
      "Saving checkpoints for 2 into /output/multi_class/multi_class3d3/model.ckpt.\n",
      "INFO:tensorflow:step = 2, loss = 6866.66\n",
      "step = 2, loss = 6866.66\n",
      "INFO:tensorflow:actual = [[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]], probabilities = [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]], reg_losses = [ 0.08764827  0.25804648  2.0341022 ]\n",
      "actual = [[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]], probabilities = [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]], reg_losses = [ 0.08764827  0.25804648  2.0341022 ]\n",
      "INFO:tensorflow:Saving checkpoints for 43 into /output/multi_class/multi_class3d3/model.ckpt.\n",
      "Saving checkpoints for 43 into /output/multi_class/multi_class3d3/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 80 into /output/multi_class/multi_class3d3/model.ckpt.\n",
      "Saving checkpoints for 80 into /output/multi_class/multi_class3d3/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.0635089\n",
      "global_step/sec: 0.0635089\n",
      "INFO:tensorflow:step = 102, loss = 2.80771e+32 (1574.585 sec)\n",
      "step = 102, loss = 2.80771e+32 (1574.585 sec)\n",
      "INFO:tensorflow:actual = [[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], probabilities = [[ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]], reg_losses = [  9.69456667e+31   6.64955744e+30   1.77175565e+32] (1574.584 sec)\n",
      "actual = [[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], probabilities = [[ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]\n",
      " [ 0.49061924  0.49055234  0.49018639  0.4903799   0.49020252  0.49020961\n",
      "   0.48967925  0.49029076  0.490051    0.49017259  0.4901998   0.49028754\n",
      "   0.49016619  0.49034515  0.49051157  0.49023333  0.48997355]], reg_losses = [  9.69456667e+31   6.64955744e+30   1.77175565e+32] (1574.584 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 119 into /output/multi_class/multi_class3d3/model.ckpt.\n",
      "Saving checkpoints for 119 into /output/multi_class/multi_class3d3/model.ckpt.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-a9ce067d82d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZoneModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"trimmed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"both\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHECKPOINT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteratorClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtsa_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInputImagesIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors_to_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-01cea8e8e477>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, tensors_to_log, reuse)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m#monitors=[logging_hook, validation_monitor])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             monitors=[logging_hook])\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsa_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             instructions)\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    291\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0m_verify_input_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m       \u001b[0mSKCompat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, steps, max_steps, monitors)\u001b[0m\n\u001b[1;32m   1348\u001b[0m                         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m                         monitors=all_monitors)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             instructions)\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    291\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    453\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_session_run_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m       \u001b[0msummary_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSummaryWriterCache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    503\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    840\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    843\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     feed_dict = self._call_hook_before_run(run_context, actual_fetches,\n\u001b[0;32m--> 944\u001b[0;31m                                            feed_dict, options)\n\u001b[0m\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;31m# Do session run.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_call_hook_before_run\u001b[0;34m(self, run_context, fetch_dict, user_feed_dict, options)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0mhook_feeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m       \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrequest\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/basic_session_run_hooks.py\u001b[0m in \u001b[0;36mbefore_run\u001b[0;34m(self, run_context)\u001b[0m\n\u001b[1;32m    674\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbefore_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     return session_run_hook.SessionRunArgs(\n\u001b[0;32m--> 676\u001b[0;31m         fetches=None, feed_dict=self.feed_fn())\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py\u001b[0m in \u001b[0;36m_feed_dict_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;31m# Add handling when queue ends.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m           \u001b[0mnext_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m           \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mput_data_array_or_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/output/tsa_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m              \u001b[0;31m#print(\"IMAGES ITERATOR \" + str(self.ids[self.i - 1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m              \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m          \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m              \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/output/tsa_utils.py\u001b[0m in \u001b[0;36mcalculate_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhorizontal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m660\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/output/tsa_utils.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(infile, vertical, horizontal, threshold)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mny\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_scale_factor'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#scaling factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#make N-d image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvertical\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bottom\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m340\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    model = ZoneModel(MODEL_ID, train_ids, \"trimmed\", \"both\", DATA_PATH, train_labels, CHECKPOINT_PATH, iteratorClass=tsa_utils.InputImagesIterator, test_ids=test_ids, test_labels=test_labels)     \n",
    "    model.train_model(tensors_to_log, reuse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_f1(model):\n",
    "    predicted = np.array([x[\"probabilities\"] for x in list(model.predict())])\n",
    "    predicted[predicted < .4] = 0\n",
    "    predicted[predicted > .4] = 1\n",
    "    predicted = predicted.flatten()\n",
    "\n",
    "    print(sklearn.metrics.f1_score(test_labels, predicted))\n",
    "    print(sklearn.metrics.precision_score(test_labels, predicted))\n",
    "    print(sklearn.metrics.recall_score(test_labels, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# model = ZoneModel(MODEL_ID, test_ids, \"both\",\"both\", DATA_PATH, test_labels, CHECKPOINT_PATH, scaler_ids=train_ids, iteratorClass=tsa_utils.ScaledImagesIterator)\n",
    "# model.load_model(checkpoint=\"1728\")\n",
    "# calculate_f1(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_model(model):\n",
    "    predicted = np.array([x[\"probabilities\"] for x in list(model.predict())])\n",
    "    predicted[predicted < .5] = 0\n",
    "    predicted[predicted > .5] = 1\n",
    "    predicted = predicted.flatten()\n",
    "    flat_train_labels = train_labels.flatten()\n",
    "    print(sklearn.metrics.f1_score(flat_train_labels, predicted))\n",
    "    print(sklearn.metrics.precision_score(flat_train_labels, predicted))\n",
    "    print(sklearn.metrics.recall_score(flat_train_labels, predicted))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# model = ZoneModel(MODEL_ID, train_ids, \"both\",\"both\", DATA_PATH, train_labels, CHECKPOINT_PATH, scaler_ids=test_ids, iteratorClass=tsa_utils.ScaledImagesIterator)\n",
    "# model.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Kaggle Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_results(model, filename):\n",
    "    eval_df = pd.read_csv(DATA_PATH + 'stage1_sample_submission.csv')\n",
    "    eval_df['zone'] = eval_df['Id'].str.split(\"_\", expand=True)[1].str.strip()\n",
    "    eval_df['id'] = eval_df['Id'].str.split(\"_\", expand=True)[0].str.strip()\n",
    "\n",
    "    eval_ids = eval_df[\"id\"].unique()\n",
    "    eval_ids.sort()\n",
    "\n",
    "    csv_file = open(CHECKPOINT_PATH + \"/\" + filename + \".csv\", \"w+\")\n",
    "    csv_file.write(\"Id,Probability\\n\")\n",
    "\n",
    "    print (\"LOADED MODEL \" + str(model))\n",
    "    predicted = np.array([x[\"probabilities\"] for x in list(model.predict())])\n",
    "    for i, image in enumerate(predicted):\n",
    "        for j, zone in enumerate(image):\n",
    "            csv_file.write(str(eval_ids[i]) + \"_Zone\" + str(j+1) + \",\" + str(zone) + \"\\n\")\n",
    "    csv_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000model4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function l2_regularizer.<locals>.l2 at 0x7f718653bae8>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0000model4\n",
      "LOADED MODEL AT STEP 300 FROM /output/multi_class/0000model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f718653bae8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.0093023255814\n",
      "0.333333333333\n",
      "0.00471698113208\n",
      "/output/multi_class 0000model4\n",
      "LOADED MODEL AT STEP 300 FROM /output/multi_class/0000model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7157ea0ea0>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.0119688809096\n",
      "0.833333333333\n",
      "0.00602772754671\n",
      "Saving results\n",
      "/output/multi_class 0000model4\n",
      "LOADED MODEL AT STEP 300 FROM /output/multi_class/0000model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f71885aab70>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75d2b94730>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0001model4\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75e114b510>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0001model4\n",
      "LOADED MODEL AT STEP 800 FROM /output/multi_class/0001model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75d1ce6f28>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.147859922179\n",
      "0.422222222222\n",
      "0.0896226415094\n",
      "/output/multi_class 0001model4\n",
      "LOADED MODEL AT STEP 800 FROM /output/multi_class/0001model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f759454b620>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.318548387097\n",
      "0.972307692308\n",
      "0.190476190476\n",
      "Saving results\n",
      "/output/multi_class 0001model4\n",
      "LOADED MODEL AT STEP 800 FROM /output/multi_class/0001model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f75943a0630>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71865d38c8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0002model4\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75944e3c80>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0002model4\n",
      "LOADED MODEL AT STEP 1500 FROM /output/multi_class/0002model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75d21737b8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.236933797909\n",
      "0.453333333333\n",
      "0.160377358491\n",
      "/output/multi_class 0002model4\n",
      "LOADED MODEL AT STEP 1500 FROM /output/multi_class/0002model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75d21737b8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.607826810991\n",
      "0.982503364738\n",
      "0.44002411091\n",
      "Saving results\n",
      "/output/multi_class 0002model4\n",
      "LOADED MODEL AT STEP 1500 FROM /output/multi_class/0002model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f71884ef588>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75d21737b8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0003model4\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7594c4a488>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0003model4\n",
      "LOADED MODEL AT STEP 2000 FROM /output/multi_class/0003model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f718822f0d0>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.315457413249\n",
      "0.47619047619\n",
      "0.235849056604\n",
      "/output/multi_class 0003model4\n",
      "LOADED MODEL AT STEP 2000 FROM /output/multi_class/0003model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75d1d1f158>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.854046732137\n",
      "0.974497681607\n",
      "0.760096443641\n",
      "Saving results\n",
      "/output/multi_class 0003model4\n",
      "LOADED MODEL AT STEP 2000 FROM /output/multi_class/0003model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f7186e72ac8>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75d1d1f158>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0010model4\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71875f2b70>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0010model4\n",
      "LOADED MODEL AT STEP 300 FROM /output/multi_class/0010model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71875419d8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.0279069767442\n",
      "1.0\n",
      "0.0141509433962\n",
      "/output/multi_class 0010model4\n",
      "LOADED MODEL AT STEP 300 FROM /output/multi_class/0010model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7186c03b70>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.00600961538462\n",
      "1.0\n",
      "0.00301386377336\n",
      "Saving results\n",
      "/output/multi_class 0010model4\n",
      "LOADED MODEL AT STEP 300 FROM /output/multi_class/0010model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f7186b27c88>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7186c03b70>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0011model4\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7187177c80>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0011model4\n",
      "LOADED MODEL AT STEP 800 FROM /output/multi_class/0011model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71869e2a60>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.197718631179\n",
      "0.509803921569\n",
      "0.122641509434\n",
      "/output/multi_class 0011model4\n",
      "LOADED MODEL AT STEP 800 FROM /output/multi_class/0011model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71869e2a60>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.345715700842\n",
      "0.969444444444\n",
      "0.21036769138\n",
      "Saving results\n",
      "/output/multi_class 0011model4\n",
      "LOADED MODEL AT STEP 800 FROM /output/multi_class/0011model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f7184ac8908>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7187ee79d8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0012model4\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7184a60ea0>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0012model4\n",
      "LOADED MODEL AT STEP 1500 FROM /output/multi_class/0012model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7157d82e18>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.262975778547\n",
      "0.493506493506\n",
      "0.179245283019\n",
      "/output/multi_class 0012model4\n",
      "LOADED MODEL AT STEP 1500 FROM /output/multi_class/0012model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71573a8510>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.625916870416\n",
      "0.966037735849\n",
      "0.462929475588\n",
      "Saving results\n",
      "/output/multi_class 0012model4\n",
      "LOADED MODEL AT STEP 1500 FROM /output/multi_class/0012model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f7157d642b0>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7184a60ea0>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0013model4\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71573a8510>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0013model4\n",
      "LOADED MODEL AT STEP 2000 FROM /output/multi_class/0013model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71573a8510>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.300653594771\n",
      "0.489361702128\n",
      "0.216981132075\n",
      "/output/multi_class 0013model4\n",
      "LOADED MODEL AT STEP 2000 FROM /output/multi_class/0013model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71574abae8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.963885429639\n",
      "0.996780424984\n",
      "0.933092224231\n",
      "Saving results\n",
      "/output/multi_class 0013model4\n",
      "LOADED MODEL AT STEP 2000 FROM /output/multi_class/0013model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f71567fa4a8>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71574abae8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0020model4\n"
     ]
    }
   ],
   "source": [
    "skip_list=[]\n",
    "for i, iterator in enumerate([tsa_utils.ScaledImagesIterator,\n",
    "                 tsa_utils.InputImagesIterator,\n",
    "                 tsa_utils.ThresholdedInputImagesIterator,\n",
    "                 tsa_utils.ThresholdedScaledImagesIterator                \n",
    "                ]):\n",
    "    for j, filter_count in enumerate([5,10,25,50]):\n",
    "        FLAT_POOL_SIZE = int(48000 * filter_count / 10)\n",
    "        for k, rv in enumerate([0.1,1.0,10.0]):\n",
    "            for l, step_count in enumerate([300, 800, 1500, 2000]):\n",
    "                STEPS=step_count\n",
    "                try:\n",
    "                    REGULARIZER_VALUE = rv\n",
    "                    FILTER_COUNT = filter_count\n",
    "                    with tf.Session() as sess:\n",
    "                        MODEL_ID = str(i) + str(j) + str(k) + str(l) + \"model4\"\n",
    "                        if MODEL_ID not in skip_list:\n",
    "                            print(MODEL_ID)\n",
    "                            model = ZoneModel(MODEL_ID, train_ids, \"trimmed\", \"both\", DATA_PATH, train_labels, CHECKPOINT_PATH, iteratorClass=iterator, scaler_ids=train_ids, test_ids=test_ids, test_labels=np.reshape(test_labels, (-1,17)))     \n",
    "                            model.train_model(tensors_to_log, reuse=False)\n",
    "                            model = ZoneModel(MODEL_ID, test_ids, \"both\",\"both\", DATA_PATH, test_labels, CHECKPOINT_PATH, scaler_ids=train_ids, iteratorClass=iterator)\n",
    "                            model.load_model()\n",
    "                            print(\"F1 Calculated\")\n",
    "                            calculate_f1(model)\n",
    "                            model = ZoneModel(MODEL_ID, train_ids, \"trimmed\", \"both\", DATA_PATH, train_labels, CHECKPOINT_PATH, iteratorClass=iterator, scaler_ids=train_ids, test_ids=test_ids, test_labels=np.reshape(test_labels, (-1,17)))     \n",
    "                            model.load_model()\n",
    "                            print(\"Validated:\")\n",
    "                            validate_model(model)\n",
    "                            print(\"Saving results\")\n",
    "                            model = ZoneModel(MODEL_ID, eval_ids, \"both\",\"both\", DATA_PATH, eval_ids, CHECKPOINT_PATH,scaler_ids=train_ids, iteratorClass=iterator)\n",
    "                            model.load_model()\n",
    "                            build_results(model, MODEL_ID)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(\"ERRORED ON \" + str(MODEL_ID))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
