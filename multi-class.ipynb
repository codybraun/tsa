{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The directory '/Users/jasminefeldmann/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\n",
      "The directory '/Users/jasminefeldmann/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: dask in /Users/jasminefeldmann/anaconda/lib/python3.6/site-packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The directory '/Users/jasminefeldmann/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\n",
      "The directory '/Users/jasminefeldmann/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: objgraph in /Users/jasminefeldmann/anaconda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: graphviz in /Users/jasminefeldmann/anaconda/lib/python3.6/site-packages (from objgraph)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "import tsa_utils\n",
    "\n",
    "from shutil import copytree\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "import pip\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "pip.main(['install', '--upgrade', 'dask'])\n",
    "pip.main(['install', 'objgraph'])\n",
    "\n",
    "import objgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copytree(\"/models/multi-class8/multi_class\", \"/output/multi_class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/output/tmp/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3616ec2511ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/output/tmp/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/output/tmp/'"
     ]
    }
   ],
   "source": [
    "#Model parameters\n",
    "BATCH_SIZE=10\n",
    "FILTER_COUNT=30\n",
    "KERNEL_SIZE1=(1,5,5)\n",
    "DEPTHSTRIDE=1\n",
    "XSTRIDE=1\n",
    "YSTRIDE=1\n",
    "POOLSIZE1=(1,3,3)\n",
    "POOLSIZE2=(1,5,5)\n",
    "POOL_STRIDES1=(1,2,2)\n",
    "POOL_STRIDES=(1,1,1)\n",
    "STEPS=10000\n",
    "XSIZE=256\n",
    "#XSIZE=512\n",
    "#XSIZE=270\n",
    "#YSIZE=340\n",
    "YSIZE=330\n",
    "#YSIZE=660\n",
    "LEARNING_RATE=0.0001\n",
    "EPSILON=0\n",
    "IMAGE_DEPTH=16\n",
    "CHANNELS=1\n",
    "FLAT_POOL_SIZE=198720\n",
    "REGULARIZER_VALUE=0.01\n",
    "\n",
    "DATA_PATH=\"/a3d_volume/\"\n",
    "CHECKPOINT_PATH=\"/output/multi_class\"\n",
    "MODEL_ID=\"multi_class3d10\"\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "os.makedirs(\"/output/tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ZoneModel():\n",
    "\n",
    "    def __init__(self, model_id, ids, x_slice, y_slice, data_path, labels, checkpoint_path=\".\", localize=False,scaler_ids=None, iteratorClass=tsa_utils.InputImagesIterator, test_ids=None, test_labels=None, randomize=False, seed=191):\n",
    "        self.model_id = model_id\n",
    "        self.ids = ids\n",
    "        self.x_slice = x_slice\n",
    "        self.y_slice = y_slice\n",
    "        self.data_path = data_path\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.labels = labels\n",
    "        self.localize = localize\n",
    "        self.scaler_ids=scaler_ids\n",
    "        self.iteratorClass = iteratorClass\n",
    "        self.test_ids = test_ids\n",
    "        self.test_labels = test_labels\n",
    "        self.randomize=randomize\n",
    "        self.seed=seed\n",
    "        \n",
    "\n",
    "    def build_model(self, data, labels, mode):\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(REGULARIZER_VALUE)\n",
    "        print(regularizer)\n",
    "        if mode != tf.contrib.learn.ModeKeys.TRAIN:\n",
    "            BATCH_SIZE=1\n",
    "        else:\n",
    "            BATCH_SIZE=10\n",
    "            \n",
    "        training = (mode==tf.contrib.learn.ModeKeys.TRAIN)\n",
    "        print(training)\n",
    "        print(XSIZE, YSIZE)\n",
    "        data = tf.reshape(data, [BATCH_SIZE, IMAGE_DEPTH, YSIZE, XSIZE, CHANNELS])\n",
    "#         normalizer = tf.contrib.layers.batch_norm(\n",
    "#             data,\n",
    "#             data_format='NHWC',  # Matching the \"cnn\" tensor which has shape (?, 9, 120, 160, 96).\n",
    "#             center=True,\n",
    "#             scale=True,\n",
    "#             is_training=training,\n",
    "#             scope='bn')\n",
    "\n",
    "        dropout = tf.layers.dropout(data, rate=0.3, training=training)\n",
    "        conv1 = tf.layers.conv3d(inputs=dropout, filters=FILTER_COUNT, kernel_size=KERNEL_SIZE1, padding=\"same\", \n",
    "                strides=(DEPTHSTRIDE,XSTRIDE,YSTRIDE), name=\"conv1\", trainable=not self.localize, kernel_regularizer=regularizer, bias_regularizer=regularizer)\n",
    "        print(conv1)\n",
    "#         pool0 = tf.layers.max_pooling3d(inputs=conv1, pool_size=POOLSIZE1, strides=POOL_STRIDES1, name=\"pool0\")\n",
    "#         print(pool0)\n",
    "#         conv2 = tf.layers.conv3d(inputs=conv1, filters=FILTER_COUNT, kernel_size=(1,3,3), padding=\"same\",\n",
    "#                 strides=(1, 2, 2), name=\"conv2\", activation=tf.nn.relu, trainable=not self.localize, kernel_regularizer=regularizer)\n",
    "#         print(conv2)\n",
    "#         pool1 = tf.layers.max_pooling3d(inputs=conv2, pool_size=POOLSIZE1, strides=POOL_STRIDES1, name=\"pool1\")\n",
    "#         print(pool1)\n",
    "#         conv3 = tf.layers.conv3d(inputs=pool1, filters=FILTER_COUNT, kernel_size=(1,3,3), padding=\"same\", \n",
    "#                 strides=(DEPTHSTRIDE,2,2), name=\"conv3\", trainable=not self.localize, kernel_regularizer=regularizer)\n",
    "#         print(conv3)\n",
    "        pool2 = tf.layers.max_pooling3d(inputs=conv1, pool_size=(1,4,4), strides=(1,2,2), name=\"pool2\")\n",
    "        print(pool2)\n",
    "        conv4 = tf.layers.conv3d(inputs=pool2, filters=FILTER_COUNT, kernel_size=(1,3,3), padding=\"same\", \n",
    "                strides=(1, 1, 1), name=\"conv4\", activation=tf.nn.relu, trainable=not self.localize, kernel_regularizer=regularizer, bias_regularizer=regularizer)\n",
    "        print(conv4)\n",
    "        conv5 = tf.layers.conv3d(inputs=conv4, filters=FILTER_COUNT, kernel_size=(1,3,3), padding=\"same\", \n",
    "            strides=(1, 1, 1), name=\"conv5\", activation=tf.nn.relu, trainable=not self.localize, kernel_regularizer=regularizer, bias_regularizer=regularizer)\n",
    "        print(conv4)\n",
    "        pool3 = tf.layers.max_pooling3d(inputs=conv5, pool_size=(1,7,7), strides=(1,7,7), name=\"pool3\")\n",
    "        print(pool3)\n",
    "        flat_pool = tf.reshape(pool3, [BATCH_SIZE, FLAT_POOL_SIZE])\n",
    "        flat_pool=tf.identity(flat_pool, name=\"flat_pool\")\n",
    "        print(flat_pool)\n",
    "#         dense = tf.layers.dense(inputs=flat_pool, units=20, trainable=True, activation=tf.nn.relu, kernel_regularizer=regularizer, bias_regularizer=regularizer)\n",
    "#         print(dense)\n",
    "        dropout2 = tf.layers.dropout(flat_pool, rate=0.3, training=training)\n",
    "        print(dropout2)\n",
    "        logits = tf.layers.dense(inputs=dropout2, units=17, trainable=True, kernel_regularizer=regularizer, bias_regularizer=regularizer)\n",
    "        logits = tf.identity(logits, name=\"logits\")\n",
    "        logits = tf.reshape(logits, [BATCH_SIZE,17])\n",
    "        reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        reg_losses = tf.identity(reg_losses, \"reg_losses\")\n",
    "        predictions = {\n",
    "            \"classes\": tf.argmax(\n",
    "              input=logits, axis=1, name=\"classes\"),\n",
    "          \"probabilities\": tf.nn.sigmoid(\n",
    "              logits, name=\"prob_tensor\")}\n",
    "        print(mode)\n",
    "        if mode == tf.contrib.learn.ModeKeys.INFER:\n",
    "            return tf.contrib.learn.ModelFnOps(mode=mode, predictions=predictions)\n",
    "        #flat_labels = tf.reshape(labels, [BATCH_SIZE, 17])\n",
    "        labels=tf.identity(labels, name=\"labels\")\n",
    "        labels = tf.cast(labels, tf.float32)\n",
    "        #class_weights=tf.reduce_sum(tf.multiply(flat_labels, tf.constant(WEIGHTS, dtype=tf.int64)), axis=1)\n",
    "        #print(class_weights)\n",
    "        #loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)\n",
    "        if mode == tf.contrib.learn.ModeKeys.TRAIN:\n",
    "            loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)) + sum(\n",
    "                    tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "        else:\n",
    "            print(\"RUNNGIN IN MODE \" + str(mode))\n",
    "            loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "#         update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "#         with tf.control_dependencies(update_ops):\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            optimizer=\"SGD\")\n",
    "\n",
    "        return tf.contrib.learn.ModelFnOps(mode=mode, predictions=predictions, loss=loss, train_op=train_op)\n",
    "\n",
    "    def train_model(self, tensors_to_log, reuse=False):\n",
    "        if reuse:\n",
    "            tsa_classifier = self.model\n",
    "        else:\n",
    "            tsa_classifier = tf.contrib.learn.Estimator(model_fn=self.build_model, \n",
    "                                                     model_dir=self.checkpoint_path + \"/\" + self.model_id)\n",
    "            \n",
    "#         validation_metrics = {\n",
    "#         \"accuracy\":\n",
    "#             tf.contrib.learn.MetricSpec(\n",
    "#                 metric_fn=tf.contrib.metrics.streaming_accuracy,\n",
    "#                 prediction_key=tf.cast(tf.reshape(tf.contrib.learn.PredictionKey.CLASSES,[1,1]), tf.bool).eval()),\n",
    "#         \"precision\":\n",
    "#             tf.contrib.learn.MetricSpec(\n",
    "#                 metric_fn=tf.contrib.metrics.streaming_precision,\n",
    "#                 prediction_key=tf.cast(tf.reshape(tf.contrib.learn.PredictionKey.CLASSES, [1,1]), tf.bool).eval()),\n",
    "#         \"recall\":\n",
    "#             tf.contrib.learn.MetricSpec(\n",
    "#                 metric_fn=tf.contrib.metrics.streaming_recall,\n",
    "#                 prediction_key=tf.cast(tf.reshape(tf.contrib.learn.PredictionKey.CLASSES, [1,1]), tf.bool).eval())\n",
    "#         }\n",
    "        \n",
    "#         validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "#             self.iteratorClass(self.test_ids, self.data_path, repeating=False, pool_size=2),\n",
    "#             tsa_utils.InputLabelsIterator(self.test_ids, self.test_labels),\n",
    "#             every_n_steps=100, early_stopping_rounds=300, metrics=validation_metrics)\n",
    "        \n",
    "        logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=100)\n",
    "        #f1_hook = calculate_f1(self.model)\n",
    "        tsa_classifier.fit(\n",
    "            #x=tsa_utils.ThresholdedInputImagesIterator(self.ids, self.data_path, 10000, self.y_slice, self.x_slice, pool_size=2), \n",
    "            x=self.iteratorClass(self.ids, self.data_path, repeating=True, pool_size=2, file_format=\".a3daps\", randomize=self.randomize, seed=self.seed),\n",
    "            y=tsa_utils.InputLabelsIterator(self.ids, self.labels, randomize=self.randomize, seed=self.seed), \n",
    "            max_steps=STEPS, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            #monitors=[logging_hook, validation_monitor])\n",
    "            monitors=[logging_hook])\n",
    "\n",
    "        self.model = tsa_classifier\n",
    "\n",
    "    def load_model(self, checkpoint=None):\n",
    "        print(self.checkpoint_path, self.model_id)\n",
    "        if checkpoint:\n",
    "            tsa_classifier = tf.contrib.learn.Estimator(model_fn=self.build_model, \n",
    "                                                    model_dir=self.checkpoint_path + \"/\" + self.model_id + \"/model.ckpt-\" + str(checkpoint))\n",
    "        else:\n",
    "            tsa_classifier = tf.contrib.learn.Estimator(model_fn=self.build_model, \n",
    "                                                    model_dir=self.checkpoint_path + \"/\" + self.model_id)\n",
    "        print (\"LOADED MODEL AT STEP \" + str(tsa_classifier.get_variable_value(\"global_step\")) + \" FROM \" + self.checkpoint_path + \"/\" + self.model_id )\n",
    "        self.model = tsa_classifier\n",
    "\n",
    "    def bootstrap_model(self, path=None):\n",
    "        if path:\n",
    "            checkpoint_path = path\n",
    "        else:\n",
    "            checkpoint_path = self.checkpoint_path + \"/\" + self.model_id\n",
    "        print (\"USING CHECKPOINT PATH  \" + checkpoint_path)\n",
    "        tsa_classifier = tf.contrib.learn.Estimator(model_fn=self.build_model, \n",
    "                                                    model_dir=checkpoint_path)\n",
    "        print (\"BOOTSTRAPPED AT STEP \" + str(tsa_classifier.get_variable_value(\"global_step\")))\n",
    "        self.model = tsa_classifier \n",
    "\n",
    "    def predict(self):\n",
    "        return self.model.predict(x=self.iteratorClass(self.ids, self.data_path, repeating=False, pool_size=2, scaler_ids=self.scaler_ids, file_format=\".a3daps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensors_to_log =  {\"probabilities\": \"prob_tensor\",\n",
    "                    \"actual\":\"labels\",\"reg_losses\":\"reg_losses\"}\n",
    "\n",
    "image_df = pd.read_csv('./stage1_flipped.csv')\n",
    "image_df['zone'] = image_df['Id'].str.split(\"_Zone\", expand=True)[1].str.strip()\n",
    "image_df['id'] = image_df['Id'].str.split(\"_\", expand=True)[0].str.strip()\n",
    "\n",
    "ids = image_df[\"id\"].unique()\n",
    "ids.sort()\n",
    "train_ids, test_ids, _, _ = train_test_split(ids, ids, test_size=.1)\n",
    "train_ids.sort()\n",
    "test_ids.sort()\n",
    "\n",
    "train_labels = image_df[image_df['id'].isin(train_ids)]\n",
    "train_labels.zone = train_labels.zone.astype(\"int\")\n",
    "train_labels = train_labels.sort_values([\"id\",\"zone\"])\n",
    "train_labels = train_labels[\"Probability\"]\n",
    "train_labels = np.reshape(train_labels, (-1,17))\n",
    "\n",
    "test_labels = image_df[image_df['id'].isin(test_ids)]\n",
    "test_labels.zone = test_labels.zone.astype(\"int\")\n",
    "test_labels = test_labels.sort_values([\"id\",\"zone\"])\n",
    "test_labels = test_labels[\"Probability\"]\n",
    "# test_labels = np.reshape(test_labels, (-1,17))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('./stage1_sample_submission.csv')\n",
    "eval_df['zone'] = eval_df['Id'].str.split(\"_\", expand=True)[1].str.strip()\n",
    "eval_df['id'] = eval_df['Id'].str.split(\"_\", expand=True)[0].str.strip()\n",
    "\n",
    "eval_ids = eval_df[\"id\"].unique()\n",
    "eval_ids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-92478c4fd9a2>:3: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From <ipython-input-15-92478c4fd9a2>:3: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From /usr/local/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "Using default config.\n",
      "INFO:tensorflow:Using config: {'_is_chief': True, '_evaluation_master': '', '_save_checkpoints_secs': 600, '_environment': 'local', '_num_worker_replicas': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_task_type': None, '_master': '', '_model_dir': '/output/multi_class/multi_class3d10', '_save_checkpoints_steps': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdc0c1a8a90>, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_session_config': None, '_task_id': 0}\n",
      "Using config: {'_is_chief': True, '_evaluation_master': '', '_save_checkpoints_secs': 600, '_environment': 'local', '_num_worker_replicas': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_task_type': None, '_master': '', '_model_dir': '/output/multi_class/multi_class3d10', '_save_checkpoints_steps': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdc0c1a8a90>, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_session_config': None, '_task_id': 0}\n",
      "WARNING:tensorflow:From <ipython-input-12-2b4f94093e30>:142: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From <ipython-input-12-2b4f94093e30>:142: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-2b4f94093e30>:142: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From <ipython-input-12-2b4f94093e30>:142: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-2b4f94093e30>:142: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From <ipython-input-12-2b4f94093e30>:142: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function l2_regularizer.<locals>.l2 at 0x7fdc5d75d158>\n",
      "True\n",
      "256 330\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 30), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 164, 127, 30), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 164, 127, 30), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 164, 127, 30), dtype=float32)\n",
      "Tensor(\"pool3/MaxPool3D:0\", shape=(10, 16, 23, 18, 30), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 198720), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 198720), dtype=float32)\n",
      "train\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /output/multi_class/multi_class3d10/model.ckpt-2535\n",
      "Restoring parameters from /output/multi_class/multi_class3d10/model.ckpt-2535\n",
      "INFO:tensorflow:Saving checkpoints for 2536 into /output/multi_class/multi_class3d10/model.ckpt.\n",
      "Saving checkpoints for 2536 into /output/multi_class/multi_class3d10/model.ckpt.\n",
      "INFO:tensorflow:step = 2536, loss = 44.8791\n",
      "step = 2536, loss = 44.8791\n",
      "INFO:tensorflow:probabilities = [[ 0.10349125  0.1138584   0.10332257  0.10223375  0.10179899  0.08388055\n",
      "   0.08555857  0.09942023  0.08320038  0.10744707  0.08796433  0.09103961\n",
      "   0.11256523  0.11537901  0.13565208  0.1093219   0.07781649]\n",
      " [ 0.10499057  0.11826451  0.10749712  0.11428835  0.10366791  0.07969235\n",
      "   0.09079922  0.09759615  0.0832285   0.10516258  0.08668093  0.09161235\n",
      "   0.10900249  0.12223251  0.1395673   0.11386897  0.07842068]\n",
      " [ 0.10548779  0.11405945  0.1031765   0.1018821   0.09894858  0.08136626\n",
      "   0.08975488  0.09681552  0.08547384  0.10410681  0.09367916  0.0954111\n",
      "   0.11110549  0.11862691  0.13430724  0.11036881  0.08123373]\n",
      " [ 0.10257019  0.11565356  0.10762419  0.10405814  0.09877775  0.08201768\n",
      "   0.09150936  0.10064844  0.08098105  0.1080329   0.08186425  0.09089863\n",
      "   0.1015119   0.11525843  0.14572939  0.1047767   0.0789666 ]\n",
      " [ 0.10159254  0.11693064  0.10951257  0.11094743  0.10099436  0.08582992\n",
      "   0.0923593   0.09742156  0.08028123  0.10683248  0.08825142  0.09214158\n",
      "   0.10494064  0.11096624  0.14720365  0.11418135  0.07333425]\n",
      " [ 0.09967364  0.11442532  0.09932451  0.10025568  0.09547184  0.08438809\n",
      "   0.08981641  0.09656563  0.07862616  0.10251102  0.0889079   0.09054228\n",
      "   0.11043837  0.11139348  0.13615736  0.1096086   0.07852677]\n",
      " [ 0.10769013  0.11321289  0.09444171  0.10842471  0.09322251  0.07648379\n",
      "   0.09154472  0.09083959  0.07761221  0.1019849   0.08495589  0.08769062\n",
      "   0.10615297  0.10706326  0.12912969  0.11016589  0.08244328]\n",
      " [ 0.10393919  0.10966358  0.1037334   0.10164763  0.0945949   0.07735983\n",
      "   0.0847716   0.09835016  0.07810029  0.10338176  0.08840278  0.08191491\n",
      "   0.10364369  0.11284191  0.13513631  0.10501054  0.08312137]\n",
      " [ 0.10342257  0.11203969  0.10110974  0.09750684  0.11076212  0.08227754\n",
      "   0.09030877  0.09218786  0.07770436  0.1002105   0.08629012  0.08923668\n",
      "   0.10079117  0.11597902  0.13753809  0.10796254  0.08157168]\n",
      " [ 0.1052928   0.11179078  0.10763557  0.11520805  0.10298158  0.08640936\n",
      "   0.08394948  0.09664877  0.07662699  0.10734604  0.09351559  0.09472762\n",
      "   0.10771098  0.11928049  0.14168876  0.11755034  0.07763609]], actual = [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]], reg_losses = [ 0.00925894  0.00002595  0.14273939  0.00003857  0.14189082  0.00010502\n",
      "  0.1630861   0.00001333]\n",
      "probabilities = [[ 0.10349125  0.1138584   0.10332257  0.10223375  0.10179899  0.08388055\n",
      "   0.08555857  0.09942023  0.08320038  0.10744707  0.08796433  0.09103961\n",
      "   0.11256523  0.11537901  0.13565208  0.1093219   0.07781649]\n",
      " [ 0.10499057  0.11826451  0.10749712  0.11428835  0.10366791  0.07969235\n",
      "   0.09079922  0.09759615  0.0832285   0.10516258  0.08668093  0.09161235\n",
      "   0.10900249  0.12223251  0.1395673   0.11386897  0.07842068]\n",
      " [ 0.10548779  0.11405945  0.1031765   0.1018821   0.09894858  0.08136626\n",
      "   0.08975488  0.09681552  0.08547384  0.10410681  0.09367916  0.0954111\n",
      "   0.11110549  0.11862691  0.13430724  0.11036881  0.08123373]\n",
      " [ 0.10257019  0.11565356  0.10762419  0.10405814  0.09877775  0.08201768\n",
      "   0.09150936  0.10064844  0.08098105  0.1080329   0.08186425  0.09089863\n",
      "   0.1015119   0.11525843  0.14572939  0.1047767   0.0789666 ]\n",
      " [ 0.10159254  0.11693064  0.10951257  0.11094743  0.10099436  0.08582992\n",
      "   0.0923593   0.09742156  0.08028123  0.10683248  0.08825142  0.09214158\n",
      "   0.10494064  0.11096624  0.14720365  0.11418135  0.07333425]\n",
      " [ 0.09967364  0.11442532  0.09932451  0.10025568  0.09547184  0.08438809\n",
      "   0.08981641  0.09656563  0.07862616  0.10251102  0.0889079   0.09054228\n",
      "   0.11043837  0.11139348  0.13615736  0.1096086   0.07852677]\n",
      " [ 0.10769013  0.11321289  0.09444171  0.10842471  0.09322251  0.07648379\n",
      "   0.09154472  0.09083959  0.07761221  0.1019849   0.08495589  0.08769062\n",
      "   0.10615297  0.10706326  0.12912969  0.11016589  0.08244328]\n",
      " [ 0.10393919  0.10966358  0.1037334   0.10164763  0.0945949   0.07735983\n",
      "   0.0847716   0.09835016  0.07810029  0.10338176  0.08840278  0.08191491\n",
      "   0.10364369  0.11284191  0.13513631  0.10501054  0.08312137]\n",
      " [ 0.10342257  0.11203969  0.10110974  0.09750684  0.11076212  0.08227754\n",
      "   0.09030877  0.09218786  0.07770436  0.1002105   0.08629012  0.08923668\n",
      "   0.10079117  0.11597902  0.13753809  0.10796254  0.08157168]\n",
      " [ 0.1052928   0.11179078  0.10763557  0.11520805  0.10298158  0.08640936\n",
      "   0.08394948  0.09664877  0.07662699  0.10734604  0.09351559  0.09472762\n",
      "   0.10771098  0.11928049  0.14168876  0.11755034  0.07763609]], actual = [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]], reg_losses = [ 0.00925894  0.00002595  0.14273939  0.00003857  0.14189082  0.00010502\n",
      "  0.1630861   0.00001333]\n",
      "INFO:tensorflow:Saving checkpoints for 2575 into /output/multi_class/multi_class3d10/model.ckpt.\n",
      "Saving checkpoints for 2575 into /output/multi_class/multi_class3d10/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 2616 into /output/multi_class/multi_class3d10/model.ckpt.\n",
      "Saving checkpoints for 2616 into /output/multi_class/multi_class3d10/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.0657059\n",
      "global_step/sec: 0.0657059\n",
      "INFO:tensorflow:step = 2636, loss = 54.2146 (1521.936 sec)\n",
      "step = 2636, loss = 54.2146 (1521.936 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.09803165  0.10145511  0.11945379  0.10668871  0.11062332  0.08059692\n",
      "   0.11419084  0.08638065  0.08800804  0.12558466  0.09877344  0.08797338\n",
      "   0.11057501  0.14259642  0.11361577  0.09886104  0.07792144]\n",
      " [ 0.09572014  0.10093489  0.11790181  0.11871219  0.10989622  0.08518107\n",
      "   0.10750917  0.09036329  0.08926851  0.11261509  0.10239818  0.08667279\n",
      "   0.11452165  0.14050044  0.11783445  0.106388    0.07835351]\n",
      " [ 0.09626664  0.10626673  0.11208557  0.10612862  0.11189241  0.08386339\n",
      "   0.10771077  0.09147111  0.08776175  0.11623807  0.09741058  0.08945804\n",
      "   0.11308252  0.1382416   0.12184329  0.1026933   0.07920776]\n",
      " [ 0.09329306  0.10372278  0.12120587  0.1097836   0.11379074  0.08804037\n",
      "   0.10394935  0.08819809  0.09573797  0.12245136  0.1019268   0.0894925\n",
      "   0.10817621  0.14389353  0.12558235  0.10697692  0.08022792]\n",
      " [ 0.09889673  0.10256574  0.11377186  0.11141858  0.11246266  0.08472908\n",
      "   0.10615923  0.08123506  0.08464926  0.11997653  0.09591782  0.08542255\n",
      "   0.11796048  0.14661038  0.11496624  0.10321759  0.07730709]\n",
      " [ 0.09680296  0.10822558  0.11016881  0.11037576  0.11412641  0.08354363\n",
      "   0.10989606  0.08892383  0.08669085  0.10996597  0.10436457  0.08218227\n",
      "   0.11701591  0.13684574  0.11935297  0.10204773  0.07480115]\n",
      " [ 0.09874494  0.10337342  0.11737815  0.11685364  0.1102557   0.08349316\n",
      "   0.1198047   0.09108531  0.08593364  0.11812432  0.10352059  0.09190405\n",
      "   0.11338336  0.1447652   0.11312874  0.09970704  0.07451397]\n",
      " [ 0.09452122  0.11053916  0.11383327  0.10762838  0.10898183  0.08441158\n",
      "   0.11933344  0.08483963  0.101059    0.11683113  0.09779198  0.08476771\n",
      "   0.11210508  0.13979851  0.1251785   0.1056773   0.07715306]\n",
      " [ 0.10008395  0.10494481  0.11700895  0.11212184  0.11549532  0.07999919\n",
      "   0.10276676  0.08480605  0.0920013   0.11930694  0.09768456  0.0853543\n",
      "   0.11925467  0.15116671  0.12113527  0.09979511  0.08327971]\n",
      " [ 0.09453359  0.10731013  0.1148394   0.10729704  0.11558145  0.08739191\n",
      "   0.10969102  0.08574168  0.09207232  0.11832425  0.09712129  0.08821274\n",
      "   0.1121427   0.14637424  0.11816878  0.0992935   0.07617948]], actual = [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]], reg_losses = [ 0.00925709  0.00002458  0.14270635  0.0000377   0.14185606  0.00010286\n",
      "  0.16307859  0.00001348] (1521.935 sec)\n",
      "probabilities = [[ 0.09803165  0.10145511  0.11945379  0.10668871  0.11062332  0.08059692\n",
      "   0.11419084  0.08638065  0.08800804  0.12558466  0.09877344  0.08797338\n",
      "   0.11057501  0.14259642  0.11361577  0.09886104  0.07792144]\n",
      " [ 0.09572014  0.10093489  0.11790181  0.11871219  0.10989622  0.08518107\n",
      "   0.10750917  0.09036329  0.08926851  0.11261509  0.10239818  0.08667279\n",
      "   0.11452165  0.14050044  0.11783445  0.106388    0.07835351]\n",
      " [ 0.09626664  0.10626673  0.11208557  0.10612862  0.11189241  0.08386339\n",
      "   0.10771077  0.09147111  0.08776175  0.11623807  0.09741058  0.08945804\n",
      "   0.11308252  0.1382416   0.12184329  0.1026933   0.07920776]\n",
      " [ 0.09329306  0.10372278  0.12120587  0.1097836   0.11379074  0.08804037\n",
      "   0.10394935  0.08819809  0.09573797  0.12245136  0.1019268   0.0894925\n",
      "   0.10817621  0.14389353  0.12558235  0.10697692  0.08022792]\n",
      " [ 0.09889673  0.10256574  0.11377186  0.11141858  0.11246266  0.08472908\n",
      "   0.10615923  0.08123506  0.08464926  0.11997653  0.09591782  0.08542255\n",
      "   0.11796048  0.14661038  0.11496624  0.10321759  0.07730709]\n",
      " [ 0.09680296  0.10822558  0.11016881  0.11037576  0.11412641  0.08354363\n",
      "   0.10989606  0.08892383  0.08669085  0.10996597  0.10436457  0.08218227\n",
      "   0.11701591  0.13684574  0.11935297  0.10204773  0.07480115]\n",
      " [ 0.09874494  0.10337342  0.11737815  0.11685364  0.1102557   0.08349316\n",
      "   0.1198047   0.09108531  0.08593364  0.11812432  0.10352059  0.09190405\n",
      "   0.11338336  0.1447652   0.11312874  0.09970704  0.07451397]\n",
      " [ 0.09452122  0.11053916  0.11383327  0.10762838  0.10898183  0.08441158\n",
      "   0.11933344  0.08483963  0.101059    0.11683113  0.09779198  0.08476771\n",
      "   0.11210508  0.13979851  0.1251785   0.1056773   0.07715306]\n",
      " [ 0.10008395  0.10494481  0.11700895  0.11212184  0.11549532  0.07999919\n",
      "   0.10276676  0.08480605  0.0920013   0.11930694  0.09768456  0.0853543\n",
      "   0.11925467  0.15116671  0.12113527  0.09979511  0.08327971]\n",
      " [ 0.09453359  0.10731013  0.1148394   0.10729704  0.11558145  0.08739191\n",
      "   0.10969102  0.08574168  0.09207232  0.11832425  0.09712129  0.08821274\n",
      "   0.1121427   0.14637424  0.11816878  0.0992935   0.07617948]], actual = [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]], reg_losses = [ 0.00925709  0.00002458  0.14270635  0.0000377   0.14185606  0.00010286\n",
      "  0.16307859  0.00001348] (1521.935 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2655 into /output/multi_class/multi_class3d10/model.ckpt.\n",
      "Saving checkpoints for 2655 into /output/multi_class/multi_class3d10/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 2694 into /output/multi_class/multi_class3d10/model.ckpt.\n",
      "Saving checkpoints for 2694 into /output/multi_class/multi_class3d10/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 2731 into /output/multi_class/multi_class3d10/model.ckpt.\n",
      "Saving checkpoints for 2731 into /output/multi_class/multi_class3d10/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.0630513\n",
      "global_step/sec: 0.0630513\n",
      "INFO:tensorflow:step = 2736, loss = 59.2783 (1586.010 sec)\n",
      "step = 2736, loss = 59.2783 (1586.010 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.09287975  0.09806443  0.11286389  0.08466405  0.07834499  0.06998649\n",
      "   0.05409028  0.10742822  0.06409762  0.07706092  0.07332101  0.09745215\n",
      "   0.09918257  0.09758762  0.06784602  0.07081281  0.06333666]\n",
      " [ 0.09701197  0.1098494   0.10314506  0.08661651  0.08368243  0.07318845\n",
      "   0.06092297  0.11330763  0.06779769  0.07830622  0.07415694  0.10554771\n",
      "   0.11177585  0.09987254  0.06750027  0.07371899  0.06202677]\n",
      " [ 0.09286734  0.10895605  0.10348274  0.0880638   0.08347531  0.07421251\n",
      "   0.0564296   0.11687475  0.06284516  0.07583883  0.07034098  0.10316071\n",
      "   0.10261495  0.0968165   0.06320065  0.07602827  0.06590888]\n",
      " [ 0.09572995  0.10594963  0.09916873  0.08216594  0.08133442  0.07537004\n",
      "   0.06082534  0.11405214  0.06723533  0.07477301  0.07512155  0.10204131\n",
      "   0.10517839  0.09199196  0.06921243  0.07474639  0.06472481]\n",
      " [ 0.09248757  0.10469551  0.10628199  0.08890947  0.08042493  0.07656516\n",
      "   0.05833862  0.11636189  0.06746238  0.07818335  0.07294022  0.10138599\n",
      "   0.11101754  0.10211988  0.07137506  0.07427136  0.06261668]\n",
      " [ 0.09425902  0.10961054  0.10416906  0.09199266  0.08124021  0.07533009\n",
      "   0.0617418   0.11155706  0.06664906  0.08195855  0.07591896  0.09744819\n",
      "   0.10935346  0.09297755  0.07347766  0.07747791  0.06619164]\n",
      " [ 0.08886928  0.10217186  0.09852339  0.08540981  0.0795938   0.07293937\n",
      "   0.05861153  0.11330085  0.06892222  0.07897909  0.07161833  0.10103197\n",
      "   0.10718047  0.09256064  0.0729852   0.07611167  0.06395321]\n",
      " [ 0.08933704  0.10125172  0.10416991  0.08512342  0.08492517  0.07257833\n",
      "   0.05918699  0.12140203  0.06696938  0.07971874  0.07426026  0.10028749\n",
      "   0.10870478  0.09937981  0.06894488  0.07947549  0.06735416]\n",
      " [ 0.08928961  0.09929252  0.10280327  0.08844041  0.08195862  0.07098301\n",
      "   0.05698807  0.11643498  0.0647878   0.07312769  0.07456376  0.09840105\n",
      "   0.11291949  0.09782754  0.06836169  0.07076352  0.0688084 ]\n",
      " [ 0.09030534  0.1001446   0.10414237  0.08844434  0.07923478  0.07384846\n",
      "   0.05608091  0.124676    0.06601606  0.07600585  0.07162075  0.0968344\n",
      "   0.1128141   0.09941938  0.07264509  0.07101188  0.06433901]], actual = [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0]], reg_losses = [ 0.00925525  0.00002874  0.14267837  0.00004187  0.14183114  0.00011746\n",
      "  0.1630967   0.00001379] (1586.010 sec)\n",
      "probabilities = [[ 0.09287975  0.09806443  0.11286389  0.08466405  0.07834499  0.06998649\n",
      "   0.05409028  0.10742822  0.06409762  0.07706092  0.07332101  0.09745215\n",
      "   0.09918257  0.09758762  0.06784602  0.07081281  0.06333666]\n",
      " [ 0.09701197  0.1098494   0.10314506  0.08661651  0.08368243  0.07318845\n",
      "   0.06092297  0.11330763  0.06779769  0.07830622  0.07415694  0.10554771\n",
      "   0.11177585  0.09987254  0.06750027  0.07371899  0.06202677]\n",
      " [ 0.09286734  0.10895605  0.10348274  0.0880638   0.08347531  0.07421251\n",
      "   0.0564296   0.11687475  0.06284516  0.07583883  0.07034098  0.10316071\n",
      "   0.10261495  0.0968165   0.06320065  0.07602827  0.06590888]\n",
      " [ 0.09572995  0.10594963  0.09916873  0.08216594  0.08133442  0.07537004\n",
      "   0.06082534  0.11405214  0.06723533  0.07477301  0.07512155  0.10204131\n",
      "   0.10517839  0.09199196  0.06921243  0.07474639  0.06472481]\n",
      " [ 0.09248757  0.10469551  0.10628199  0.08890947  0.08042493  0.07656516\n",
      "   0.05833862  0.11636189  0.06746238  0.07818335  0.07294022  0.10138599\n",
      "   0.11101754  0.10211988  0.07137506  0.07427136  0.06261668]\n",
      " [ 0.09425902  0.10961054  0.10416906  0.09199266  0.08124021  0.07533009\n",
      "   0.0617418   0.11155706  0.06664906  0.08195855  0.07591896  0.09744819\n",
      "   0.10935346  0.09297755  0.07347766  0.07747791  0.06619164]\n",
      " [ 0.08886928  0.10217186  0.09852339  0.08540981  0.0795938   0.07293937\n",
      "   0.05861153  0.11330085  0.06892222  0.07897909  0.07161833  0.10103197\n",
      "   0.10718047  0.09256064  0.0729852   0.07611167  0.06395321]\n",
      " [ 0.08933704  0.10125172  0.10416991  0.08512342  0.08492517  0.07257833\n",
      "   0.05918699  0.12140203  0.06696938  0.07971874  0.07426026  0.10028749\n",
      "   0.10870478  0.09937981  0.06894488  0.07947549  0.06735416]\n",
      " [ 0.08928961  0.09929252  0.10280327  0.08844041  0.08195862  0.07098301\n",
      "   0.05698807  0.11643498  0.0647878   0.07312769  0.07456376  0.09840105\n",
      "   0.11291949  0.09782754  0.06836169  0.07076352  0.0688084 ]\n",
      " [ 0.09030534  0.1001446   0.10414237  0.08844434  0.07923478  0.07384846\n",
      "   0.05608091  0.124676    0.06601606  0.07600585  0.07162075  0.0968344\n",
      "   0.1128141   0.09941938  0.07264509  0.07101188  0.06433901]], actual = [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0]], reg_losses = [ 0.00925525  0.00002874  0.14267837  0.00004187  0.14183114  0.00011746\n",
      "  0.1630967   0.00001379] (1586.010 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2770 into /output/multi_class/multi_class3d10/model.ckpt.\n",
      "Saving checkpoints for 2770 into /output/multi_class/multi_class3d10/model.ckpt.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-92478c4fd9a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZoneModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"trimmed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"both\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHECKPOINT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteratorClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtsa_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampledImagesIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10009\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_variables\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_variables\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors_to_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-2b4f94093e30>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, tensors_to_log, reuse)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;31m#monitors=[logging_hook, validation_monitor])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             monitors=[logging_hook])\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsa_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             instructions)\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    291\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0m_verify_input_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m       \u001b[0mSKCompat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, steps, max_steps, monitors)\u001b[0m\n\u001b[1;32m   1348\u001b[0m                         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m                         monitors=all_monitors)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             instructions)\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    291\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    453\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_session_run_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m       \u001b[0msummary_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSummaryWriterCache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    503\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    840\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    843\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     feed_dict = self._call_hook_before_run(run_context, actual_fetches,\n\u001b[0;32m--> 944\u001b[0;31m                                            feed_dict, options)\n\u001b[0m\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;31m# Do session run.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_call_hook_before_run\u001b[0;34m(self, run_context, fetch_dict, user_feed_dict, options)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0mhook_feeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m       \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrequest\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/training/basic_session_run_hooks.py\u001b[0m in \u001b[0;36mbefore_run\u001b[0;34m(self, run_context)\u001b[0m\n\u001b[1;32m    674\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbefore_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     return session_run_hook.SessionRunArgs(\n\u001b[0;32m--> 676\u001b[0;31m         fetches=None, feed_dict=self.feed_fn())\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py\u001b[0m in \u001b[0;36m_feed_dict_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;31m# Add handling when queue ends.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m           \u001b[0mnext_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m           \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mput_data_array_or_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/output/tsa_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m              \u001b[0;31m#print(\"IMAGES ITERATOR \" + str(self.ids[self.i - 1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m              \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m          \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m              \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/output/tsa_utils.py\u001b[0m in \u001b[0;36mcalculate_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;31m#print(\"IMAGE ITERATOR \" + str(j))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhorizontal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m660\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/skimage/measure/block.py\u001b[0m in \u001b[0;36mblock_reduce\u001b[0;34m(image, block_size, func, cval)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     image = np.pad(image, pad_width=pad_width, mode='constant',\n\u001b[0;32m---> 72\u001b[0;31m                    constant_values=cval)\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mview_as_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`pad_width` must be of integral type.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m     \u001b[0mnarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m     \u001b[0mpad_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    model = ZoneModel(MODEL_ID, train_ids, \"trimmed\", \"both\", DATA_PATH, train_labels, CHECKPOINT_PATH, iteratorClass=tsa_utils.SampledImagesIterator, test_ids=test_ids, test_labels=test_labels, randomize=True, seed=10009)     \n",
    "    sess.run( tf.initialize_variables( list( tf.get_variable(name) for name in sess.run( tf.report_uninitialized_variables( tf.all_variables( ) ) ) ) ) )\n",
    "    model.train_model(tensors_to_log, reuse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_f1(model):\n",
    "    predicted = np.array([x[\"probabilities\"] for x in list(model.predict())])\n",
    "    predicted[predicted < .4] = 0\n",
    "    predicted[predicted > .4] = 1\n",
    "    predicted = predicted.flatten()\n",
    "\n",
    "    print(sklearn.metrics.f1_score(test_labels, predicted))\n",
    "    print(sklearn.metrics.precision_score(test_labels, predicted))\n",
    "    print(sklearn.metrics.recall_score(test_labels, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/output/multi_class multi_class3d3\n",
      "INFO:tensorflow:Using default config.\n",
      "Using default config.\n",
      "INFO:tensorflow:Using config: {'_evaluation_master': '', '_tf_random_seed': None, '_num_ps_replicas': 0, '_environment': 'local', '_session_config': None, '_task_id': 0, '_num_worker_replicas': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6b1f38c50>, '_model_dir': '/output/multi_class/multi_class3d3', '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_task_type': None, '_keep_checkpoint_max': 5}\n",
      "Using config: {'_evaluation_master': '', '_tf_random_seed': None, '_num_ps_replicas': 0, '_environment': 'local', '_session_config': None, '_task_id': 0, '_num_worker_replicas': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6b1f38c50>, '_model_dir': '/output/multi_class/multi_class3d3', '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_task_type': None, '_keep_checkpoint_max': 5}\n",
      "LOADED MODEL AT STEP 1509 FROM /output/multi_class/multi_class3d3\n",
      "WARNING:tensorflow:From <ipython-input-28-d8000311d107>:160: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From <ipython-input-28-d8000311d107>:160: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function l2_regularizer.<locals>.l2 at 0x7fb6b1ebbae8>\n",
      "False\n",
      "256 330\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 64, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 32, 110, 85, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 32, 110, 85, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 1496000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 1496000), dtype=float32)\n",
      "infer\n",
      "INFO:tensorflow:Restoring parameters from /output/multi_class/multi_class3d3/model.ckpt-1509\n",
      "Restoring parameters from /output/multi_class/multi_class3d3/model.ckpt-1509\n",
      "0.18115942029\n",
      "0.342465753425\n",
      "0.12315270936\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ZoneModel(MODEL_ID, test_ids, \"both\",\"both\", DATA_PATH, test_labels, CHECKPOINT_PATH, scaler_ids=train_ids, iteratorClass=tsa_utils.InputImagesIterator)\n",
    "model.load_model()\n",
    "calculate_f1(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_model(model):\n",
    "    predicted = np.array([x[\"probabilities\"] for x in list(model.predict())])\n",
    "    predicted[predicted < .5] = 0\n",
    "    predicted[predicted > .5] = 1\n",
    "    predicted = predicted.flatten()\n",
    "    flat_train_labels = train_labels.flatten()\n",
    "    print(sklearn.metrics.f1_score(flat_train_labels, predicted))\n",
    "    print(sklearn.metrics.precision_score(flat_train_labels, predicted))\n",
    "    print(sklearn.metrics.recall_score(flat_train_labels, predicted))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/output/multi_class multi_class3d3\n",
      "INFO:tensorflow:Using default config.\n",
      "Using default config.\n",
      "INFO:tensorflow:Using config: {'_evaluation_master': '', '_tf_random_seed': None, '_num_ps_replicas': 0, '_environment': 'local', '_session_config': None, '_task_id': 0, '_num_worker_replicas': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6b1c5ad30>, '_model_dir': '/output/multi_class/multi_class3d3', '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_task_type': None, '_keep_checkpoint_max': 5}\n",
      "Using config: {'_evaluation_master': '', '_tf_random_seed': None, '_num_ps_replicas': 0, '_environment': 'local', '_session_config': None, '_task_id': 0, '_num_worker_replicas': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6b1c5ad30>, '_model_dir': '/output/multi_class/multi_class3d3', '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_task_type': None, '_keep_checkpoint_max': 5}\n",
      "LOADED MODEL AT STEP 1509 FROM /output/multi_class/multi_class3d3\n",
      "WARNING:tensorflow:From <ipython-input-28-d8000311d107>:160: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From <ipython-input-28-d8000311d107>:160: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function l2_regularizer.<locals>.l2 at 0x7fb6b266e8c8>\n",
      "False\n",
      "256 330\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 64, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 32, 110, 85, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 32, 110, 85, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 1496000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 1496000), dtype=float32)\n",
      "infer\n",
      "INFO:tensorflow:Restoring parameters from /output/multi_class/multi_class3d3/model.ckpt-1509\n",
      "Restoring parameters from /output/multi_class/multi_class3d3/model.ckpt-1509\n",
      "0.992453969212\n",
      "0.999392097264\n",
      "0.985611510791\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ZoneModel(MODEL_ID, train_ids, \"both\",\"both\", DATA_PATH, train_labels, CHECKPOINT_PATH, scaler_ids=test_ids, iteratorClass=tsa_utils.InputImagesIterator)\n",
    "model.load_model()\n",
    "validate_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Kaggle Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_results(model, filename):\n",
    "    eval_df = pd.read_csv(DATA_PATH + 'stage1_sample_submission.csv')\n",
    "    eval_df['zone'] = eval_df['Id'].str.split(\"_\", expand=True)[1].str.strip()\n",
    "    eval_df['id'] = eval_df['Id'].str.split(\"_\", expand=True)[0].str.strip()\n",
    "\n",
    "    eval_ids = eval_df[\"id\"].unique()\n",
    "    eval_ids.sort()\n",
    "\n",
    "    csv_file = open(CHECKPOINT_PATH + \"/\" + filename + \".csv\", \"w+\")\n",
    "    csv_file.write(\"Id,Probability\\n\")\n",
    "\n",
    "    print (\"LOADED MODEL \" + str(model))\n",
    "    predicted = np.array([x[\"probabilities\"] for x in list(model.predict())])\n",
    "    for i, image in enumerate(predicted):\n",
    "        for j, zone in enumerate(image):\n",
    "            csv_file.write(str(eval_ids[i]) + \"_Zone\" + str(j+1) + \",\" + str(zone) + \"\\n\")\n",
    "    csv_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000model4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function l2_regularizer.<locals>.l2 at 0x7f718653bae8>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0000model4\n",
      "LOADED MODEL AT STEP 300 FROM /output/multi_class/0000model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f718653bae8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.0093023255814\n",
      "0.333333333333\n",
      "0.00471698113208\n",
      "/output/multi_class 0000model4\n",
      "LOADED MODEL AT STEP 300 FROM /output/multi_class/0000model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7157ea0ea0>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.0119688809096\n",
      "0.833333333333\n",
      "0.00602772754671\n",
      "Saving results\n",
      "/output/multi_class 0000model4\n",
      "LOADED MODEL AT STEP 300 FROM /output/multi_class/0000model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f71885aab70>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75d2b94730>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0001model4\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75e114b510>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0001model4\n",
      "LOADED MODEL AT STEP 800 FROM /output/multi_class/0001model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75d1ce6f28>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.147859922179\n",
      "0.422222222222\n",
      "0.0896226415094\n",
      "/output/multi_class 0001model4\n",
      "LOADED MODEL AT STEP 800 FROM /output/multi_class/0001model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f759454b620>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.318548387097\n",
      "0.972307692308\n",
      "0.190476190476\n",
      "Saving results\n",
      "/output/multi_class 0001model4\n",
      "LOADED MODEL AT STEP 800 FROM /output/multi_class/0001model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f75943a0630>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71865d38c8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0002model4\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75944e3c80>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0002model4\n",
      "LOADED MODEL AT STEP 1500 FROM /output/multi_class/0002model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75d21737b8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.236933797909\n",
      "0.453333333333\n",
      "0.160377358491\n",
      "/output/multi_class 0002model4\n",
      "LOADED MODEL AT STEP 1500 FROM /output/multi_class/0002model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75d21737b8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.607826810991\n",
      "0.982503364738\n",
      "0.44002411091\n",
      "Saving results\n",
      "/output/multi_class 0002model4\n",
      "LOADED MODEL AT STEP 1500 FROM /output/multi_class/0002model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f71884ef588>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75d21737b8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0003model4\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7594c4a488>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0003model4\n",
      "LOADED MODEL AT STEP 2000 FROM /output/multi_class/0003model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f718822f0d0>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.315457413249\n",
      "0.47619047619\n",
      "0.235849056604\n",
      "/output/multi_class 0003model4\n",
      "LOADED MODEL AT STEP 2000 FROM /output/multi_class/0003model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75d1d1f158>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.854046732137\n",
      "0.974497681607\n",
      "0.760096443641\n",
      "Saving results\n",
      "/output/multi_class 0003model4\n",
      "LOADED MODEL AT STEP 2000 FROM /output/multi_class/0003model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f7186e72ac8>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f75d1d1f158>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0010model4\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71875f2b70>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0010model4\n",
      "LOADED MODEL AT STEP 300 FROM /output/multi_class/0010model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71875419d8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.0279069767442\n",
      "1.0\n",
      "0.0141509433962\n",
      "/output/multi_class 0010model4\n",
      "LOADED MODEL AT STEP 300 FROM /output/multi_class/0010model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7186c03b70>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.00600961538462\n",
      "1.0\n",
      "0.00301386377336\n",
      "Saving results\n",
      "/output/multi_class 0010model4\n",
      "LOADED MODEL AT STEP 300 FROM /output/multi_class/0010model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f7186b27c88>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7186c03b70>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0011model4\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7187177c80>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0011model4\n",
      "LOADED MODEL AT STEP 800 FROM /output/multi_class/0011model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71869e2a60>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.197718631179\n",
      "0.509803921569\n",
      "0.122641509434\n",
      "/output/multi_class 0011model4\n",
      "LOADED MODEL AT STEP 800 FROM /output/multi_class/0011model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71869e2a60>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.345715700842\n",
      "0.969444444444\n",
      "0.21036769138\n",
      "Saving results\n",
      "/output/multi_class 0011model4\n",
      "LOADED MODEL AT STEP 800 FROM /output/multi_class/0011model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f7184ac8908>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7187ee79d8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0012model4\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7184a60ea0>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0012model4\n",
      "LOADED MODEL AT STEP 1500 FROM /output/multi_class/0012model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7157d82e18>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.262975778547\n",
      "0.493506493506\n",
      "0.179245283019\n",
      "/output/multi_class 0012model4\n",
      "LOADED MODEL AT STEP 1500 FROM /output/multi_class/0012model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71573a8510>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.625916870416\n",
      "0.966037735849\n",
      "0.462929475588\n",
      "Saving results\n",
      "/output/multi_class 0012model4\n",
      "LOADED MODEL AT STEP 1500 FROM /output/multi_class/0012model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f7157d642b0>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f7184a60ea0>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0013model4\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71573a8510>\n",
      "256 330\n",
      "True\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(10, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(10, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(10, 24000), dtype=float32)\n",
      "train\n",
      "/output/multi_class 0013model4\n",
      "LOADED MODEL AT STEP 2000 FROM /output/multi_class/0013model4\n",
      "F1 Calculated\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71573a8510>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.300653594771\n",
      "0.489361702128\n",
      "0.216981132075\n",
      "/output/multi_class 0013model4\n",
      "LOADED MODEL AT STEP 2000 FROM /output/multi_class/0013model4\n",
      "Validated:\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71574abae8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0.963885429639\n",
      "0.996780424984\n",
      "0.933092224231\n",
      "Saving results\n",
      "/output/multi_class 0013model4\n",
      "LOADED MODEL AT STEP 2000 FROM /output/multi_class/0013model4\n",
      "LOADED MODEL <__main__.ZoneModel object at 0x7f71567fa4a8>\n",
      "<function l2_regularizer.<locals>.l2 at 0x7f71574abae8>\n",
      "256 330\n",
      "False\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 330, 256, 5), dtype=float32)\n",
      "Tensor(\"pool0/MaxPool3D:0\", shape=(1, 16, 164, 127, 5), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 165, 128, 5), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 16, 82, 63, 5), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 16, 41, 32, 5), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool3D:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 16, 20, 15, 5), dtype=float32)\n",
      "Tensor(\"flat_pool:0\", shape=(1, 24000), dtype=float32)\n",
      "Tensor(\"dropout_2/Identity:0\", shape=(1, 24000), dtype=float32)\n",
      "infer\n",
      "0020model4\n"
     ]
    }
   ],
   "source": [
    "skip_list=[]\n",
    "for i, iterator in enumerate([tsa_utils.ScaledImagesIterator,\n",
    "                 tsa_utils.InputImagesIterator,\n",
    "                 tsa_utils.ThresholdedInputImagesIterator,\n",
    "                 tsa_utils.ThresholdedScaledImagesIterator                \n",
    "                ]):\n",
    "    for j, filter_count in enumerate([5,10,25,50]):\n",
    "        FLAT_POOL_SIZE = int(48000 * filter_count / 10)\n",
    "        for k, rv in enumerate([0.1,1.0,10.0]):\n",
    "            for l, step_count in enumerate([300, 800, 1500, 2000]):\n",
    "                STEPS=step_count\n",
    "                try:\n",
    "                    REGULARIZER_VALUE = rv\n",
    "                    FILTER_COUNT = filter_count\n",
    "                    with tf.Session() as sess:\n",
    "                        MODEL_ID = str(i) + str(j) + str(k) + str(l) + \"model4\"\n",
    "                        if MODEL_ID not in skip_list:\n",
    "                            print(MODEL_ID)\n",
    "                            model = ZoneModel(MODEL_ID, train_ids, \"trimmed\", \"both\", DATA_PATH, train_labels, CHECKPOINT_PATH, iteratorClass=iterator, scaler_ids=train_ids, test_ids=test_ids, test_labels=np.reshape(test_labels, (-1,17)))     \n",
    "                            model.train_model(tensors_to_log, reuse=False)\n",
    "                            model = ZoneModel(MODEL_ID, test_ids, \"both\",\"both\", DATA_PATH, test_labels, CHECKPOINT_PATH, scaler_ids=train_ids, iteratorClass=iterator)\n",
    "                            model.load_model()\n",
    "                            print(\"F1 Calculated\")\n",
    "                            calculate_f1(model)\n",
    "                            model = ZoneModel(MODEL_ID, train_ids, \"trimmed\", \"both\", DATA_PATH, train_labels, CHECKPOINT_PATH, iteratorClass=iterator, scaler_ids=train_ids, test_ids=test_ids, test_labels=np.reshape(test_labels, (-1,17)))     \n",
    "                            model.load_model()\n",
    "                            print(\"Validated:\")\n",
    "                            validate_model(model)\n",
    "                            print(\"Saving results\")\n",
    "                            model = ZoneModel(MODEL_ID, eval_ids, \"both\",\"both\", DATA_PATH, eval_ids, CHECKPOINT_PATH,scaler_ids=train_ids, iteratorClass=iterator)\n",
    "                            model.load_model()\n",
    "                            build_results(model, MODEL_ID)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(\"ERRORED ON \" + str(MODEL_ID))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array = np.array([0, 1 , 1 ,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 4, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
