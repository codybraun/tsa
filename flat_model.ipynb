{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import tensorflow as tf\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import math \n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "import tsa_utils\n",
    "import deep_cnn\n",
    "import mini_cnn\n",
    "\n",
    "from shutil import copytree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model parameters\n",
    "BATCH_SIZE=10\n",
    "FILTER_COUNT=24\n",
    "KERNEL_SIZE1=(1,6,6)\n",
    "DEPTHSTRIDE=1\n",
    "XSTRIDE=1\n",
    "YSTRIDE=1\n",
    "POOLSIZE1=(16,3,3)\n",
    "POOLSIZE2=(3,3)\n",
    "POOL_STRIDES1=(1,2,2)\n",
    "POOL_STRIDES=(1,1)\n",
    "STEPS=3000\n",
    "XSIZE=392\n",
    "#XSIZE=512\n",
    "SIZE=660\n",
    "#XSIZE=270\n",
    "YSIZE=340\n",
    "LEARNING_RATE=0.001\n",
    "IMAGE_DEPTH=16\n",
    "CHANNELS=1\n",
    "WEIGHTS=[1, 5]\n",
    "FLAT_POOL_SIZE=43680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH=\"/data_volume/\"\n",
    "CHECKPOINT_PATH=\"/output/new_output2\"\n",
    "MODEL_ID=\"tsa_nb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import tensorflow as tf\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "import tsa_utils\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "class ZoneModel():\n",
    "\n",
    "    def __init__(self, model_id, ids, zone, x_slice, y_slice, data_path, labels, checkpoint_path=\".\", localize=False):\n",
    "        self.model_id = model_id\n",
    "        self.ids = ids\n",
    "        self.zone = zone if zone else \"\"\n",
    "        self.x_slice = x_slice\n",
    "        self.y_slice = y_slice\n",
    "        self.data_path = data_path\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.labels = labels\n",
    "        self.localize = localize\n",
    "\n",
    "    def build_model(self, data, labels, mode):\n",
    "        if mode == tf.contrib.learn.ModeKeys.INFER:\n",
    "            BATCH_SIZE=1\n",
    "        else:\n",
    "            BATCH_SIZE=10\n",
    "        print(XSIZE, YSIZE)\n",
    "        data = tf.reshape(data, [BATCH_SIZE, IMAGE_DEPTH, YSIZE, XSIZE, CHANNELS])\n",
    "        conv1 = tf.layers.conv3d(inputs=data, filters=FILTER_COUNT, kernel_size=KERNEL_SIZE1, padding=\"same\", \n",
    "                strides=(DEPTHSTRIDE,XSTRIDE,YSTRIDE), name=\"conv1\", trainable=not self.localize)\n",
    "        print(conv1)\n",
    "        conv2 = tf.layers.conv3d(inputs=conv1, filters=FILTER_COUNT, kernel_size=(3,3,3), padding=\"same\",\n",
    "                strides=(1, 2, 1), name=\"conv2\", activation=tf.nn.relu, trainable=not self.localize)\n",
    "        print(conv2)\n",
    "        pool1 = tf.layers.max_pooling3d(inputs=conv2, pool_size=POOLSIZE1, strides=POOL_STRIDES1, name=\"pool1\")\n",
    "        print(pool1)\n",
    "        flattener = tf.reshape(pool1, [BATCH_SIZE, 84, 195, 24])\n",
    "        pool2 = tf.layers.max_pooling2d(inputs=flattener, pool_size=(3,3), strides=(3,3), name=\"pool2\")\n",
    "        print(pool2)\n",
    "        conv3 = tf.layers.conv2d(inputs=pool2, filters=FILTER_COUNT, kernel_size=(3,3), padding=\"same\", \n",
    "                strides=(XSTRIDE,YSTRIDE), name=\"conv3\", trainable=not self.localize)\n",
    "        print(conv3)\n",
    "        pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=(2,2), strides=POOL_STRIDES, name=\"pool1\")\n",
    "        print(pool3)\n",
    "        conv4 = tf.layers.conv2d(inputs=pool3, filters=FILTER_COUNT, kernel_size=(3,3), padding=\"same\", \n",
    "                strides=(1, 1), name=\"conv4\", activation=tf.nn.relu, trainable=not self.localize)\n",
    "        print(conv4)\n",
    "        pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=POOLSIZE2, strides=POOL_STRIDES, name=\"pool2\", padding=\"same\")\n",
    "        print(pool4)\n",
    "        flat_pool = tf.reshape(pool2, [BATCH_SIZE, FLAT_POOL_SIZE])\n",
    "        flat_pool=tf.identity(flat_pool, name=\"flat_pool\")\n",
    "\n",
    "        logits = tf.layers.dense(inputs=flat_pool, units=2, trainable=True)\n",
    "        logits = tf.identity(logits, name=\"logits\")\n",
    "        logits = tf.reshape(logits, [BATCH_SIZE,2])\n",
    "        predictions = {\n",
    "            \"classes\": tf.argmax(\n",
    "              input=logits, axis=1, name=\"classes\"),\n",
    "          \"probabilities\": tf.nn.softmax(\n",
    "              logits, name=\"softmax_tensor\")}\n",
    "\n",
    "        if mode == tf.contrib.learn.ModeKeys.TRAIN:\n",
    "            flat_labels = tf.reshape(labels, [BATCH_SIZE, 2])\n",
    "            test_labels=tf.identity(flat_labels, name=\"labels\")\n",
    "            class_weights=tf.reduce_sum(tf.multiply(flat_labels, tf.constant(WEIGHTS, dtype=tf.int64)), axis=1)\n",
    "            loss = tf.losses.softmax_cross_entropy(onehot_labels=test_labels, logits=logits, weights=class_weights)\n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "                loss=loss,\n",
    "                global_step=tf.contrib.framework.get_global_step(),\n",
    "                learning_rate=LEARNING_RATE,\n",
    "                optimizer=\"SGD\")\n",
    "        if mode == tf.contrib.learn.ModeKeys.INFER:\n",
    "            return tf.contrib.learn.ModelFnOps(mode=mode, predictions=predictions)\n",
    "        return tf.contrib.learn.ModelFnOps(mode=mode, predictions=predictions, loss=loss, train_op=train_op)\n",
    "\n",
    "    def train_model(self, tensors_to_log, reuse=False):\n",
    "        if reuse:\n",
    "            tsa_classifier = self.model\n",
    "        else:\n",
    "            tsa_classifier = tf.contrib.learn.Estimator(model_fn=self.build_model, \n",
    "                                                     model_dir=self.checkpoint_path + \"/\" + self.model_id + self.zone)\n",
    "        logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=100)\n",
    "        tsa_classifier.fit(\n",
    "            x=InputImagesIterator(self.ids, self.data_path, 10000, self.y_slice, self.x_slice), \n",
    "            y=InputLabelsIterator(self.ids, self.labels), \n",
    "            steps=STEPS, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            monitors=[logging_hook])\n",
    "        self.model = tsa_classifier\n",
    "\n",
    "    def load_model(self):\n",
    "        tsa_classifier = tf.contrib.learn.Estimator(model_fn=self.build_model, \n",
    "                                                    model_dir=self.checkpoint_path + \"/\" + self.model_id + self.zone)\n",
    "        print (\"LOADED MODEL AT STEP \" + str(tsa_classifier.get_variable_value(\"global_step\")) + \" FROM \" + self.checkpoint_path + \"/\" + self.model_id + self.zone)\n",
    "        self.model = tsa_classifier\n",
    "\n",
    "    def bootstrap_model(self, path=None):\n",
    "        if path:\n",
    "            checkpoint_path = path\n",
    "        else:\n",
    "            checkpoint_path = self.checkpoint_path + \"/\" + self.model_id + self.zone\n",
    "        print (\"USING CHECKPOINT PATH  \" + checkpoint_path)\n",
    "        tsa_classifier = tf.contrib.learn.Estimator(model_fn=self.build_model, \n",
    "                                                    model_dir=checkpoint_path)\n",
    "        print (\"BOOTSTRAPPED AT STEP \" + str(tsa_classifier.get_variable_value(\"global_step\")))\n",
    "        self.model = tsa_classifier \n",
    "\n",
    "    def predict(self):\n",
    "        return self.model.predict(x=InputImagesIterator(self.ids, \n",
    "                                                            self.data_path, \n",
    "                                                            10000, \n",
    "                                                            self.y_slice,\n",
    "                                                            self.x_slice, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_df = pd.read_csv(DATA_PATH + '/stage1_labels.csv')\n",
    "image_df['zone'] = image_df['Id'].str.split(\"_\", expand=True)[1].str.strip()\n",
    "image_df['id'] = image_df['Id'].str.split(\"_\", expand=True)[0].str.strip()\n",
    "\n",
    "ids = image_df[\"id\"].unique()\n",
    "ids.sort()\n",
    "training_ids = ids\n",
    "\n",
    "labels = image_df[image_df['id'].isin(training_ids)]\n",
    "labels = labels.sort_values(\"id\")\n",
    "\n",
    "tensors_to_log =  {\"probabilities\": \"softmax_tensor\",\n",
    "                    \"actual\":\"labels\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slice_locations = {1:(\"top\",\"right\"),\n",
    "\t2:(\"middle\",\"right\"), \n",
    "\t3:(\"top\",\"left\"),\n",
    "\t4:(\"middle\",\"left\"),\n",
    "\t5:(\"top\",\"middle\"),\n",
    "\t6:(\"top\",\"right\"),\n",
    "\t7:(\"top\",\"left\"),\n",
    "\t8:(\"middle\",\"right\"),\n",
    "\t9:(\"middle\",\"middle\"),\n",
    "\t10:(\"middle\",\"left\"),\n",
    "\t11:(\"bottom\",\"right\"),\n",
    "\t12:(\"bottom\",\"left\"),\n",
    "\t13:(\"bottom\",\"right\"),\n",
    "\t14:(\"bottom\",\"left\"),\n",
    "\t15:(\"bottom\",\"right\"),\n",
    "\t16:(\"bottom\",\"left\"),\n",
    "\t17:(\"top\",\"middle\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FITTING MODEL FOR ZONE 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FITTING MODEL FOR ZONE 3\n",
      "FITTING MODEL FOR ZONE 4\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa1f5d2fd90>, '_model_dir': '/output/new_output2/tsa_nbZone4', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "WARNING:tensorflow:From <ipython-input-19-85cfbd074acc>:94: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-19-85cfbd074acc>:94: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-19-85cfbd074acc>:94: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "(392, 340)\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(10, 16, 340, 392, 24), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(10, 16, 170, 392, 24), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(10, 1, 84, 195, 24), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool:0\", shape=(10, 28, 65, 24), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(10, 28, 65, 24), dtype=float32)\n",
      "Tensor(\"pool1_2/MaxPool:0\", shape=(10, 27, 64, 24), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(10, 27, 64, 24), dtype=float32)\n",
      "Tensor(\"pool2_2/MaxPool:0\", shape=(10, 27, 64, 24), dtype=float32)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /output/new_output2/tsa_nbZone4/model.ckpt-115\n",
      "INFO:tensorflow:Saving checkpoints for 116 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.28939, step = 116\n",
      "INFO:tensorflow:probabilities = [[ 0.58227932  0.41772071]\n",
      " [ 0.61414295  0.38585702]\n",
      " [ 0.59801775  0.40198225]\n",
      " [ 0.68439996  0.3156001 ]\n",
      " [ 0.55538058  0.44461942]\n",
      " [ 0.59991062  0.40008938]\n",
      " [ 0.6392228   0.36077726]\n",
      " [ 0.70471555  0.29528448]\n",
      " [ 0.60474318  0.39525685]\n",
      " [ 0.67568541  0.32431462]], actual = [[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "INFO:tensorflow:global_step/sec: 0.188568\n",
      "INFO:tensorflow:loss = 0.768072, step = 216 (530.315 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.60869813  0.3913019 ]\n",
      " [ 0.65815675  0.34184325]\n",
      " [ 0.62087744  0.37912253]\n",
      " [ 0.56250715  0.43749282]\n",
      " [ 0.51962119  0.48037881]\n",
      " [ 0.59972644  0.40027347]\n",
      " [ 0.66636711  0.33363289]\n",
      " [ 0.46521008  0.53478986]\n",
      " [ 0.58536243  0.41463757]\n",
      " [ 0.62050825  0.37949178]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]] (530.315 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 230 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189219\n",
      "INFO:tensorflow:loss = 0.376347, step = 316 (528.487 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.77470344  0.22529657]\n",
      " [ 0.67707741  0.32292259]\n",
      " [ 0.743047    0.256953  ]\n",
      " [ 0.58979839  0.41020164]\n",
      " [ 0.53935659  0.46064332]\n",
      " [ 0.74954987  0.25045022]\n",
      " [ 0.76571077  0.23428921]\n",
      " [ 0.75127453  0.24872552]\n",
      " [ 0.70220172  0.29779828]\n",
      " [ 0.61808586  0.38191411]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (528.487 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 344 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189216\n",
      "INFO:tensorflow:loss = 0.341988, step = 416 (528.495 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.77239144  0.22760864]\n",
      " [ 0.57895154  0.42104846]\n",
      " [ 0.58862412  0.41137588]\n",
      " [ 0.64336109  0.35663891]\n",
      " [ 0.74077237  0.25922757]\n",
      " [ 0.74644524  0.25355476]\n",
      " [ 0.72646928  0.27353075]\n",
      " [ 0.7809028   0.21909718]\n",
      " [ 0.77756876  0.22243123]\n",
      " [ 0.79206085  0.20793912]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (528.494 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 458 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189466\n",
      "INFO:tensorflow:loss = 1.21417, step = 516 (527.800 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.436708    0.56329203]\n",
      " [ 0.79947293  0.20052704]\n",
      " [ 0.73391223  0.2660878 ]\n",
      " [ 0.68107021  0.31892985]\n",
      " [ 0.76292312  0.23707689]\n",
      " [ 0.80220556  0.19779445]\n",
      " [ 0.57426631  0.42573369]\n",
      " [ 0.74981517  0.25018486]\n",
      " [ 0.77376616  0.22623387]\n",
      " [ 0.88275146  0.11724851]], actual = [[0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]] (527.800 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 572 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.188934\n",
      "INFO:tensorflow:loss = 0.814486, step = 616 (529.285 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.80114454  0.1988555 ]\n",
      " [ 0.40390706  0.596093  ]\n",
      " [ 0.52913553  0.47086444]\n",
      " [ 0.73203021  0.26796976]\n",
      " [ 0.78261578  0.2173842 ]\n",
      " [ 0.54172868  0.45827135]\n",
      " [ 0.83213443  0.1678656 ]\n",
      " [ 0.55562824  0.44437176]\n",
      " [ 0.38505742  0.61494261]\n",
      " [ 0.72089607  0.27910393]], actual = [[1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]] (529.285 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 686 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189005\n",
      "INFO:tensorflow:loss = 0.998097, step = 716 (529.087 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.72539884  0.27460116]\n",
      " [ 0.94368666  0.05631333]\n",
      " [ 0.57443941  0.4255605 ]\n",
      " [ 0.77367085  0.22632918]\n",
      " [ 0.95762473  0.04237521]\n",
      " [ 0.60527241  0.39472756]\n",
      " [ 0.93313557  0.06686443]\n",
      " [ 0.95322967  0.0467703 ]\n",
      " [ 0.85752833  0.14247167]\n",
      " [ 0.89429444  0.10570552]], actual = [[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (529.087 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 800 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.18865\n",
      "INFO:tensorflow:loss = 0.47221, step = 816 (530.082 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.92405927  0.07594072]\n",
      " [ 0.77466506  0.22533494]\n",
      " [ 0.92153358  0.07846644]\n",
      " [ 0.48299715  0.51700276]\n",
      " [ 0.9317196   0.06828041]\n",
      " [ 0.88346475  0.11653531]\n",
      " [ 0.77024972  0.22975032]\n",
      " [ 0.89228958  0.10771038]\n",
      " [ 0.71742547  0.28257447]\n",
      " [ 0.89958107  0.10041894]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (530.082 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 914 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.188908\n",
      "INFO:tensorflow:loss = 0.2843, step = 916 (529.359 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.8518762   0.1481238 ]\n",
      " [ 0.75627196  0.24372803]\n",
      " [ 0.89996403  0.100036  ]\n",
      " [ 0.42473593  0.5752641 ]\n",
      " [ 0.60172045  0.39827958]\n",
      " [ 0.91319436  0.08680567]\n",
      " [ 0.79279572  0.20720425]\n",
      " [ 0.69677359  0.30322635]\n",
      " [ 0.95154643  0.04845357]\n",
      " [ 0.81895334  0.18104661]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (529.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.189229\n",
      "INFO:tensorflow:loss = 0.893568, step = 1016 (528.460 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.4910903   0.50890964]\n",
      " [ 0.47195202  0.52804798]\n",
      " [ 0.7916041   0.20839588]\n",
      " [ 0.77494276  0.22505727]\n",
      " [ 0.93210196  0.06789802]\n",
      " [ 0.79869443  0.20130557]\n",
      " [ 0.38564336  0.61435664]\n",
      " [ 0.42799181  0.57200819]\n",
      " [ 0.4764621   0.52353787]\n",
      " [ 0.41304135  0.58695859]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]] (528.459 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1028 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189477\n",
      "INFO:tensorflow:loss = 0.960438, step = 1116 (527.768 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.33523101  0.66476899]\n",
      " [ 0.80959141  0.19040857]\n",
      " [ 0.97864771  0.02135229]\n",
      " [ 0.58162558  0.41837436]\n",
      " [ 0.97054905  0.02945091]\n",
      " [ 0.55545074  0.44454932]\n",
      " [ 0.82198948  0.17801055]\n",
      " [ 0.66451621  0.33548379]\n",
      " [ 0.6918084   0.3081916 ]\n",
      " [ 0.86518633  0.13481364]], actual = [[0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]] (527.768 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1142 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.188846\n",
      "INFO:tensorflow:loss = 0.408141, step = 1216 (529.531 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.32911074  0.67088926]\n",
      " [ 0.77487344  0.22512649]\n",
      " [ 0.66304928  0.33695069]\n",
      " [ 0.73330486  0.26669511]\n",
      " [ 0.53353071  0.46646932]\n",
      " [ 0.71910316  0.28089681]\n",
      " [ 0.76321214  0.23678783]\n",
      " [ 0.78757548  0.21242455]\n",
      " [ 0.96076024  0.0392398 ]\n",
      " [ 0.61455369  0.38544631]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (529.531 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1256 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.18907\n",
      "INFO:tensorflow:loss = 0.713585, step = 1316 (528.905 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.55490947  0.44509053]\n",
      " [ 0.38588521  0.61411482]\n",
      " [ 0.9054808   0.09451915]\n",
      " [ 0.46416074  0.5358392 ]\n",
      " [ 0.91818029  0.0818197 ]\n",
      " [ 0.92315656  0.07684348]\n",
      " [ 0.9665572   0.03344274]\n",
      " [ 0.59498382  0.40501618]\n",
      " [ 0.98824382  0.01175619]\n",
      " [ 0.85234958  0.14765048]], actual = [[1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (528.905 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1370 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189421\n",
      "INFO:tensorflow:loss = 0.250825, step = 1416 (527.925 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.97814298  0.02185703]\n",
      " [ 0.94816518  0.05183485]\n",
      " [ 0.9316299   0.06837007]\n",
      " [ 0.99365777  0.00634221]\n",
      " [ 0.9723714   0.02762865]\n",
      " [ 0.83210617  0.16789381]\n",
      " [ 0.99223596  0.00776397]\n",
      " [ 0.86573166  0.13426833]\n",
      " [ 0.99184668  0.00815335]\n",
      " [ 0.32750052  0.67249942]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]] (527.925 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1484 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189373\n",
      "INFO:tensorflow:loss = 0.124959, step = 1516 (528.057 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.7871545   0.21284544]\n",
      " [ 0.9756285   0.02437153]\n",
      " [ 0.96740234  0.03259759]\n",
      " [ 0.86837667  0.1316233 ]\n",
      " [ 0.97324908  0.0267509 ]\n",
      " [ 0.65039563  0.34960431]\n",
      " [ 0.87724215  0.12275787]\n",
      " [ 0.93477672  0.06522328]\n",
      " [ 0.902978    0.09702196]\n",
      " [ 0.9478606   0.05213938]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (528.057 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1598 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189357\n",
      "INFO:tensorflow:loss = 0.374611, step = 1616 (528.102 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.43886861  0.56113142]\n",
      " [ 0.86872035  0.13127965]\n",
      " [ 0.53429365  0.46570635]\n",
      " [ 0.44053751  0.55946243]\n",
      " [ 0.70485985  0.29514015]\n",
      " [ 0.76978087  0.23021913]\n",
      " [ 0.78562504  0.21437496]\n",
      " [ 0.93640655  0.06359342]\n",
      " [ 0.85913956  0.14086041]\n",
      " [ 0.7671783   0.23282172]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (528.102 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1712 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.18949\n",
      "INFO:tensorflow:loss = 0.357353, step = 1716 (527.733 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.88519287  0.11480714]\n",
      " [ 0.84043682  0.1595632 ]\n",
      " [ 0.9597528   0.04024716]\n",
      " [ 0.9551121   0.04488788]\n",
      " [ 0.99147499  0.00852497]\n",
      " [ 0.93869883  0.06130112]\n",
      " [ 0.98313957  0.01686041]\n",
      " [ 0.40274888  0.59725118]\n",
      " [ 0.98617297  0.01382699]\n",
      " [ 0.59995466  0.40004539]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]] (527.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.189294\n",
      "INFO:tensorflow:loss = 0.065934, step = 1816 (528.280 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.98105812  0.01894188]\n",
      " [ 0.94490248  0.05509754]\n",
      " [ 0.9849807   0.0150193 ]\n",
      " [ 0.99256057  0.00743944]\n",
      " [ 0.99884999  0.00115005]\n",
      " [ 0.99770796  0.00229206]\n",
      " [ 0.91354948  0.08645048]\n",
      " [ 0.98036677  0.01963322]\n",
      " [ 0.64399397  0.35600606]\n",
      " [ 0.99284124  0.00715875]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (528.280 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1826 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189231\n",
      "INFO:tensorflow:loss = 0.16342, step = 1916 (528.456 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.63254231  0.36745763]\n",
      " [ 0.76803851  0.23196149]\n",
      " [ 0.98014361  0.01985643]\n",
      " [ 0.99583411  0.00416584]\n",
      " [ 0.99578661  0.00421339]\n",
      " [ 0.93427879  0.06572126]\n",
      " [ 0.14222446  0.85777551]\n",
      " [ 0.99295348  0.00704658]\n",
      " [ 0.96311718  0.03688283]\n",
      " [ 0.99587822  0.00412178]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (528.456 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1940 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189252\n",
      "INFO:tensorflow:loss = 0.0581414, step = 2016 (528.396 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.9936645   0.00633551]\n",
      " [ 0.71581435  0.28418568]\n",
      " [ 0.9993338   0.00066618]\n",
      " [ 0.9632054   0.03679452]\n",
      " [ 0.89736784  0.10263211]\n",
      " [ 0.93705446  0.06294558]\n",
      " [ 0.98044628  0.01955372]\n",
      " [ 0.99952066  0.00047931]\n",
      " [ 0.99896896  0.00103109]\n",
      " [ 0.99202514  0.00797494]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (528.396 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2054 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189246\n",
      "INFO:tensorflow:loss = 0.150589, step = 2116 (528.413 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.97191185  0.0280882 ]\n",
      " [ 0.99186057  0.00813947]\n",
      " [ 0.55367899  0.44632104]\n",
      " [ 0.9133082   0.08669175]\n",
      " [ 0.98544794  0.01455208]\n",
      " [ 0.70345914  0.29654092]\n",
      " [ 0.99895298  0.00104698]\n",
      " [ 0.83045858  0.16954148]\n",
      " [ 0.99705851  0.00294149]\n",
      " [ 0.04518694  0.95481312]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]] (528.413 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2168 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189435\n",
      "INFO:tensorflow:loss = 0.0873247, step = 2216 (527.886 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.12205818  0.87794185]\n",
      " [ 0.99352974  0.0064703 ]\n",
      " [ 0.99299908  0.0070009 ]\n",
      " [ 0.96487337  0.03512662]\n",
      " [ 0.91887856  0.08112145]\n",
      " [ 0.96985561  0.03014444]\n",
      " [ 0.97506976  0.0249302 ]\n",
      " [ 0.97977912  0.02022091]\n",
      " [ 0.99791092  0.00208901]\n",
      " [ 0.98992926  0.01007075]], actual = [[0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (527.886 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2282 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189426\n",
      "INFO:tensorflow:loss = 0.067175, step = 2316 (527.912 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.9851265   0.01487352]\n",
      " [ 0.98168474  0.0183153 ]\n",
      " [ 0.99333584  0.00666414]\n",
      " [ 0.98053437  0.01946561]\n",
      " [ 0.99985301  0.00014694]\n",
      " [ 0.81327313  0.18672691]\n",
      " [ 0.81733483  0.18266523]\n",
      " [ 0.99992061  0.00007941]\n",
      " [ 0.87843269  0.12156727]\n",
      " [ 0.92895156  0.07104846]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (527.912 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2396 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.18938\n",
      "INFO:tensorflow:loss = 0.0909157, step = 2416 (528.038 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.89096838  0.10903164]\n",
      " [ 0.9996137   0.00038633]\n",
      " [ 0.99563181  0.00436827]\n",
      " [ 0.98640347  0.01359655]\n",
      " [ 0.99713993  0.00286015]\n",
      " [ 0.99989641  0.00010354]\n",
      " [ 0.99612337  0.00387665]\n",
      " [ 0.99997461  0.00002543]\n",
      " [ 0.04329854  0.95670146]\n",
      " [ 0.10363903  0.89636099]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]] (528.038 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2510 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.18925\n",
      "INFO:tensorflow:loss = 0.0722558, step = 2516 (528.401 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.98588264  0.0141174 ]\n",
      " [ 0.95421708  0.04578298]\n",
      " [ 0.0406707   0.95932937]\n",
      " [ 0.97274065  0.0272594 ]\n",
      " [ 0.99557883  0.00442114]\n",
      " [ 0.99464983  0.00535024]\n",
      " [ 0.99987352  0.00012648]\n",
      " [ 0.98452282  0.01547713]\n",
      " [ 0.99363774  0.00636225]\n",
      " [ 0.07583636  0.92416358]], actual = [[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]] (528.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.189457\n",
      "INFO:tensorflow:loss = 0.0926149, step = 2616 (527.824 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.99851984  0.00148018]\n",
      " [ 0.99498111  0.00501887]\n",
      " [ 0.99757993  0.00241998]\n",
      " [ 0.99997663  0.00002332]\n",
      " [ 0.96920645  0.03079357]\n",
      " [ 0.99105936  0.00894058]\n",
      " [ 0.87877804  0.12122196]\n",
      " [ 0.99622774  0.00377229]\n",
      " [ 0.9827404   0.01725966]\n",
      " [ 0.48358932  0.51641065]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (527.824 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2624 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189118\n",
      "INFO:tensorflow:loss = 0.0553239, step = 2716 (528.771 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.99881136  0.00118866]\n",
      " [ 0.99496377  0.00503621]\n",
      " [ 0.99678242  0.00321755]\n",
      " [ 0.88185334  0.11814667]\n",
      " [ 0.07238042  0.92761964]\n",
      " [ 0.9992938   0.0007062 ]\n",
      " [ 0.97521871  0.02478132]\n",
      " [ 0.99240583  0.0075942 ]\n",
      " [ 0.99931228  0.00068778]\n",
      " [ 0.99176425  0.00823575]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (528.771 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2738 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.188971\n",
      "INFO:tensorflow:loss = 0.0293511, step = 2816 (529.182 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.98914635  0.01085365]\n",
      " [ 0.99997103  0.00002891]\n",
      " [ 0.99792153  0.0020785 ]\n",
      " [ 0.99848622  0.00151385]\n",
      " [ 0.99785787  0.00214209]\n",
      " [ 0.04425332  0.95574671]\n",
      " [ 0.99698961  0.00301036]\n",
      " [ 0.99678195  0.00321805]\n",
      " [ 0.99625397  0.00374601]\n",
      " [ 0.96028388  0.03971616]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (529.182 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2852 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189344\n",
      "INFO:tensorflow:loss = 0.0492431, step = 2916 (528.140 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.96504939  0.03495055]\n",
      " [ 0.7155779   0.28442216]\n",
      " [ 0.9435491   0.05645097]\n",
      " [ 0.99952316  0.00047687]\n",
      " [ 0.99625301  0.00374696]\n",
      " [ 0.97653759  0.02346247]\n",
      " [ 0.98870587  0.01129405]\n",
      " [ 0.99706632  0.00293373]\n",
      " [ 0.98342854  0.01657144]\n",
      " [ 0.99490935  0.00509061]], actual = [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (528.140 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2966 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.189404\n",
      "INFO:tensorflow:loss = 0.0888078, step = 3016 (527.972 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.99682581  0.00317418]\n",
      " [ 0.98227435  0.01772571]\n",
      " [ 0.06657381  0.9334262 ]\n",
      " [ 0.99867237  0.00132763]\n",
      " [ 0.07325926  0.92674077]\n",
      " [ 0.89072788  0.10927216]\n",
      " [ 0.99634957  0.00365044]\n",
      " [ 0.99624509  0.00375491]\n",
      " [ 0.98259145  0.01740862]\n",
      " [ 0.9998858   0.00011424]], actual = [[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]] (527.973 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3080 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 3115 into /output/new_output2/tsa_nbZone4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0663192.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\tfor zone in range(2,5):\n",
    "\t\tprint(\"FITTING MODEL FOR ZONE \" + str(zone))\n",
    "\t\ttrain_labels = labels[labels[\"zone\"]==\"Zone\"+str(zone)]\n",
    "\t\ttrain_labels[\"class0\"] = 0\n",
    "\t\ttrain_labels[\"class1\"] = 0\n",
    "\t\ttrain_labels.loc[train_labels['Probability'] == 0, 'class0'] = 1\n",
    "\t\ttrain_labels.loc[train_labels['Probability'] == 1, 'class1'] = 1\n",
    "\t\ttrain_labels = np.reshape(np.array(train_labels[[\"class0\",\"class1\"]]), [-1,2])\n",
    "        #model = ZoneModel(MODEL_ID, training_ids, \"Zone\" + str(zone), slice_locations[zone][1], slice_locations[zone][0], DATA_PATH, train_labels, CHECKPOINT_PATH, localize=False)\n",
    "        model = ZoneModel(MODEL_ID, training_ids, \"Zone\" + str(zone), \"trimmed\", slice_locations[zone][0], DATA_PATH, train_labels, CHECKPOINT_PATH, localize=False)     \n",
    "        model.train_model(tensors_to_log, reuse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy in data from pervious model if needed \n",
    "from shutil import copytree\n",
    "\n",
    "for zone in range(1,18):\n",
    "\tcopytree(\"/models/tsa_nbZone\" + str(zone), \"/output/tsa_nbZone\" +str(zone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING MODEL FOR ZONE 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa1dfc27f10>, '_model_dir': './tsa_nbZone4', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "LOADED MODEL AT STEP 531 FROM ./tsa_nbZone4\n",
      "LOADED MODEL <__main__.ZoneModel instance at 0x7fa1dfe0e638>\n",
      "WARNING:tensorflow:From <ipython-input-19-85cfbd074acc>:119: calling predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "(392, 340)\n",
      "Tensor(\"conv1/BiasAdd:0\", shape=(1, 16, 340, 392, 24), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 16, 170, 392, 24), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool3D:0\", shape=(1, 1, 84, 195, 24), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool:0\", shape=(1, 28, 65, 24), dtype=float32)\n",
      "Tensor(\"conv3/BiasAdd:0\", shape=(1, 28, 65, 24), dtype=float32)\n",
      "Tensor(\"pool1_2/MaxPool:0\", shape=(1, 27, 64, 24), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 27, 64, 24), dtype=float32)\n",
      "Tensor(\"pool2_2/MaxPool:0\", shape=(1, 27, 64, 24), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from ./tsa_nbZone4/model.ckpt-531\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Assign requires shapes of both tensors to match. lhs shape= [43680,2] rhs shape= [59136,2]\n\t [[Node: save/Assign_9 = Assign[T=DT_FLOAT, _class=[\"loc:@dense/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](dense/kernel, save/RestoreV2_9/_3)]]\n\nCaused by op u'save/Assign_9', defined at:\n  File \"/usr/local/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/local/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-2f285b4f2347>\", line 42, in <module>\n    predicted = np.array([x[\"probabilities\"][1] for x in list(model.predict())])\n  File \"<ipython-input-19-85cfbd074acc>\", line 119, in predict\n    self.x_slice, False))\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 289, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 590, in predict\n    as_iterable=as_iterable)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 890, in _infer_model\n    config=self._session_config))\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 648, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 477, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 822, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 827, in _create_session\n    return self._sess_creator.create_session()\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 538, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 403, in create_session\n    self._scaffold.finalize()\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 203, in finalize\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 736, in _get_saver_or_default\n    saver = Saver(sharded=True, allow_empty=True)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1139, in __init__\n    self.build()\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1170, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 687, in build\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 450, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/state_ops.py\", line 271, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 45, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [43680,2] rhs shape= [59136,2]\n\t [[Node: save/Assign_9 = Assign[T=DT_FLOAT, _class=[\"loc:@dense/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](dense/kernel, save/RestoreV2_9/_3)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2f285b4f2347>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"LOADED MODEL \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probabilities\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mcsv_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_Zone\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\",\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-85cfbd074acc>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m                                                             \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_slice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                                                             self.x_slice, False))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.pyc\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             instructions)\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    291\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, input_fn, batch_size, outputs, as_iterable)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mfeed_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         as_iterable=as_iterable)\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_variable_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36m_infer_model\u001b[0;34m(self, input_fn, feed_fn, outputs, as_iterable, iterate_batches)\u001b[0m\n\u001b[1;32m    888\u001b[0m               \u001b[0mcheckpoint_filename_with_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m               \u001b[0mscaffold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfer_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaffold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m               config=self._session_config))\n\u001b[0m\u001b[1;32m    891\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mas_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    646\u001b[0m     super(MonitoredSession, self).__init__(\n\u001b[1;32m    647\u001b[0m         \u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    475\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess_creator)\u001b[0m\n\u001b[1;32m    820\u001b[0m     \"\"\"\n\u001b[1;32m    821\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36m_create_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         logging.info('An error was raised while a session was being created. '\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m       \u001b[0;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m       \u001b[0;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0minit_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0minit_feed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         init_fn=self._scaffold.init_fn)\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.pyc\u001b[0m in \u001b[0;36mprepare_session\u001b[0;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         config=config)\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_loaded_from_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minit_fn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_init_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.pyc\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[0;34m(self, master, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint_filename_with_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m       \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_filename_with_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1548\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [43680,2] rhs shape= [59136,2]\n\t [[Node: save/Assign_9 = Assign[T=DT_FLOAT, _class=[\"loc:@dense/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](dense/kernel, save/RestoreV2_9/_3)]]\n\nCaused by op u'save/Assign_9', defined at:\n  File \"/usr/local/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/local/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-2f285b4f2347>\", line 42, in <module>\n    predicted = np.array([x[\"probabilities\"][1] for x in list(model.predict())])\n  File \"<ipython-input-19-85cfbd074acc>\", line 119, in predict\n    self.x_slice, False))\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 289, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 590, in predict\n    as_iterable=as_iterable)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 890, in _infer_model\n    config=self._session_config))\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 648, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 477, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 822, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 827, in _create_session\n    return self._sess_creator.create_session()\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 538, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 403, in create_session\n    self._scaffold.finalize()\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 203, in finalize\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 736, in _get_saver_or_default\n    saver = Saver(sharded=True, allow_empty=True)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1139, in __init__\n    self.build()\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1170, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 687, in build\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 450, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/state_ops.py\", line 271, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 45, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [43680,2] rhs shape= [59136,2]\n\t [[Node: save/Assign_9 = Assign[T=DT_FLOAT, _class=[\"loc:@dense/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](dense/kernel, save/RestoreV2_9/_3)]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import tensorflow as tf\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import math \n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "import tsa_utils\n",
    "import mini_cnn\n",
    "\n",
    "image_df = pd.read_csv(DATA_PATH + 'stage1_sample_submission.csv')\n",
    "image_df['zone'] = image_df['Id'].str.split(\"_\", expand=True)[1].str.strip()\n",
    "image_df['id'] = image_df['Id'].str.split(\"_\", expand=True)[0].str.strip()\n",
    "\n",
    "ids = image_df[\"id\"].unique()\n",
    "ids.sort()\n",
    "labels = image_df[image_df['id'].isin(ids)]\n",
    "all_labels = labels.sort_values(\"id\")\n",
    "\n",
    "csv_file = open(CHECKPOINT_PATH + \"/submission.csv\", \"w+\")\n",
    "csv_file.write(\"Id,Probability\\n\")\n",
    "for zone in range(4,5):\n",
    "\tprint(\"EVALUATING MODEL FOR ZONE \" + str(zone))\n",
    "\tlabels = all_labels[all_labels[\"zone\"]==\"Zone\"+str(zone)]\n",
    "\tlabels[\"class0\"] = 0\n",
    "\tlabels[\"class1\"] = 0\n",
    "\tlabels.loc[labels['Probability'] == 0, 'class0'] = 1\n",
    "\tlabels.loc[labels['Probability'] == 1, 'class1'] = 1\n",
    "\tlabels = np.reshape(np.array(labels[[\"class0\",\"class1\"]]), [-1,2])\n",
    "\n",
    "\tmodel = ZoneModel(MODEL_ID, ids, \"Zone\" + str(zone), slice_locations[zone][1], slice_locations[zone][0], DATA_PATH, image_df)\n",
    "\t#model = ZoneModel(MODEL_ID, ids, \"Zone\" + str(zone), \"both\", \"both\", DATA_PATH, labels, checkpoint_path=CHECKPOINT_PATH)\n",
    "\tmodel.load_model()\n",
    "\tprint (\"LOADED MODEL \" + str(model))\n",
    "\tpredicted = np.array([x[\"probabilities\"][1] for x in list(model.predict())])\n",
    "\tfor i, prediction in enumerate(predicted):\n",
    "\t\tcsv_file.write(str(ids[i]) + \"_Zone\" + str(zone) + \",\" + str(prediction) + \"\\n\")\n",
    "csv_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "def read_header(infile):\n",
    "    \"\"\"Read image header (first 512 bytes)\n",
    "    \"\"\"\n",
    "    h = dict()\n",
    "    fid = open(infile, 'rb')\n",
    "    h['filename'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 20))\n",
    "    h['parent_filename'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 20))\n",
    "    h['comments1'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 80))\n",
    "    h['comments2'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 80))\n",
    "    h['energy_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['config_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['file_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['trans_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scan_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['data_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['date_modified'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 16))\n",
    "    h['frequency'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['mat_velocity'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['num_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_polarization_channels'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['spare00'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['adc_min_voltage'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['adc_max_voltage'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['band_width'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['spare01'] = np.fromfile(fid, dtype = np.int16, count = 5)\n",
    "    h['polarization_type'] = np.fromfile(fid, dtype = np.int16, count = 4)\n",
    "    h['record_header_size'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['word_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['word_precision'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['min_data_value'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['max_data_value'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['avg_data_value'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['data_scale_factor'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['data_units'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['surf_removal'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['edge_weighting'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['x_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['y_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['z_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['t_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['spare02'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['x_return_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_return_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_return_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['scan_orientation'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scan_direction'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['data_storage_order'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scanner_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['x_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['t_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['num_x_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_y_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_z_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_t_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['x_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_acc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_acc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_acc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_motor_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_motor_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_motor_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_encoder_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_encoder_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_encoder_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['date_processed'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 8))\n",
    "    h['time_processed'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 8))\n",
    "    h['depth_recon'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_max_travel'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_max_travel'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['elevation_offset_angle'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['roll_offset_angle'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_max_travel'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['azimuth_offset_angle'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['adc_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['spare06'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scanner_radius'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_offset'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_offset'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_offset'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['t_delay'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['range_gate_start'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['range_gate_end'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['ahis_software_version'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['spare_end'] = np.fromfile(fid, dtype = np.float32, count = 10)\n",
    "    return h\n",
    "\n",
    "\n",
    "def read_data(infile, vertical=\"both\", horizontal=\"both\"):\n",
    "    \"\"\"Read any of the 4 types of image files, returns a numpy array of the image contents\n",
    "    \"\"\"\n",
    "    extension = os.path.splitext(infile)[1]\n",
    "    h = read_header(infile)\n",
    "    nx = int(h['num_x_pts'])\n",
    "    ny = int(h['num_y_pts'])\n",
    "    nt = int(h['num_t_pts'])\n",
    "    fid = open(infile, 'rb')\n",
    "    fid.seek(512) #skip header\n",
    "    if extension == '.aps' or extension == '.a3daps':\n",
    "        if(h['word_type']==7): #float32\n",
    "            data = np.fromfile(fid, dtype = np.float32, count = nx * ny * nt)\n",
    "        elif(h['word_type']==4): #uint16\n",
    "            data = np.fromfile(fid, dtype = np.uint16, count = nx * ny * nt)\n",
    "        data = data * h['data_scale_factor'] #scaling factor\n",
    "        data = data.reshape(nx, ny, nt, order='F').copy() #make N-d image\n",
    "        if vertical == \"bottom\":\n",
    "            data = data[:, :340, :] \n",
    "        elif vertical == \"top\":\n",
    "            data = data[:, 320:660, :] \n",
    "        elif vertical == \"middle\":\n",
    "            data = data[:, 170:510, :] \n",
    "        rotated_data = []\n",
    "        if horizontal == \"right\":\n",
    "            for i in range(0,16):\n",
    "                increment = 10\n",
    "                rotated_data.append(data[(i * increment) + 50:(i * increment) + 320,:,i])\n",
    "        elif horizontal == \"left\":\n",
    "            for i in range(0,16):\n",
    "                increment = 10\n",
    "                rotated_data.append(data[210 - (i * increment): 480-(i * increment):,:,i])\n",
    "        elif horizontal == \"middle\":\n",
    "            for i in range(0,16):\n",
    "                increment = 10\n",
    "                rotated_data.append(data[130:400,:,i])\n",
    "        elif horizontal == \"trimmed\":\n",
    "            for i in range(0,16):\n",
    "                rotated_data.append(data[60:-60:,:,i])\n",
    "        else:\n",
    "            for i in range(0,16):\n",
    "                rotated_data.append(data[:,:,i])\n",
    "        data = np.array(rotated_data)  \n",
    "    elif extension == '.a3d':\n",
    "        if(h['word_type']==7): #float32\n",
    "            data = np.fromfile(fid, dtype = np.float32, count = nx * ny * nt)\n",
    "        elif(h['word_type']==4): #uint16\n",
    "            data = np.fromfile(fid, dtype = np.uint16, count = nx * ny * nt)\n",
    "        data = data * h['data_scale_factor'] #scaling factor\n",
    "        data = data.reshape(nx, nt, ny, order='F').copy() #make N-d image\n",
    "    elif extension == '.ahi':\n",
    "        data = np.fromfile(fid, dtype = np.float32, count = 2* nx * ny * nt)\n",
    "        data = data.reshape(2, ny, nx, nt, order='F').copy()\n",
    "        real = data[0,:,:,:].copy()\n",
    "        imag = data[1,:,:,:].copy()\n",
    "    fid.close()\n",
    "    if extension != '.ahi':\n",
    "        return np.swapaxes(data, 2, 1)\n",
    "    else:\n",
    "        return real, imag\n",
    "\n",
    "class InputImagesIterator:\n",
    "    def __init__(self, ids, data_path, contrast=1, vertical=\"both\", horizontal=\"both\", repeating=True):\n",
    "        self.ids=ids\n",
    "        self.contrast = contrast\n",
    "        self.data_path=data_path\n",
    "        self.i = -1\n",
    "        self.vertical = vertical\n",
    "        self.horizontal = horizontal\n",
    "        self.repeating = repeating\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def next(self):\n",
    "        # print (\"id \" + str(self.ids[self.i-1])) \n",
    "        # print(\"image iter \" + str(self.i))\n",
    "        if self.i < len(self.ids) -1:\n",
    "            self.i = self.i + 1\n",
    "            #print(\"IMAGES ITERATOR \" + str(self.ids[self.i - 1]))\n",
    "            return np.stack(read_data(self.data_path + self.ids[self.i] + \".aps\", self.vertical, self.horizontal) * self.contrast)\n",
    "        else:\n",
    "            if not self.repeating:\n",
    "                raise StopIteration()\n",
    "            #Restart iteration, cycle back through\n",
    "            self.i = -1\n",
    "            return np.stack(read_data(self.data_path + self.ids[0] + \".aps\", self.vertical, self.horizontal) * self.contrast)\n",
    "\n",
    "class InputLabelsIterator:\n",
    "    def __init__(self, ids, labels):\n",
    "        self.ids=ids\n",
    "        self.labels=labels\n",
    "        self.i=-1\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def next(self):\n",
    "        #print(\"in label iter \" + str(self.ids[self.i -1])) \n",
    "        #print(\"in label iter \" + str(self.test_labels[self.i -1])) \n",
    "        #print(\"label iter \" + str(self.i))\n",
    "        if self.i < len(self.ids) -1:\n",
    "            self.i = self.i + 1\n",
    "            #print(\"LABEL\" + str(self.test_labels[self.i -1]))\n",
    "            return(self.labels[self.i])\n",
    "        else:\n",
    "            #Restart iteration, cycle back through\n",
    "            self.i = -1\n",
    "            #raise StopIteration()\n",
    "            return(self.labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
