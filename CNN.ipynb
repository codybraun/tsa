{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import png\n",
    "import tensorflow as tf\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_header(infile):\n",
    "    \"\"\"Read image header (first 512 bytes)\n",
    "    \"\"\"\n",
    "    h = dict()\n",
    "    fid = open(infile, 'r+b')\n",
    "    h['filename'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 20))\n",
    "    h['parent_filename'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 20))\n",
    "    h['comments1'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 80))\n",
    "    h['comments2'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 80))\n",
    "    h['energy_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['config_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['file_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['trans_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scan_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['data_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['date_modified'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 16))\n",
    "    h['frequency'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['mat_velocity'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['num_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_polarization_channels'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['spare00'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['adc_min_voltage'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['adc_max_voltage'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['band_width'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['spare01'] = np.fromfile(fid, dtype = np.int16, count = 5)\n",
    "    h['polarization_type'] = np.fromfile(fid, dtype = np.int16, count = 4)\n",
    "    h['record_header_size'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['word_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['word_precision'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['min_data_value'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['max_data_value'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['avg_data_value'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['data_scale_factor'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['data_units'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['surf_removal'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['edge_weighting'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['x_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['y_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['z_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['t_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['spare02'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['x_return_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_return_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_return_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['scan_orientation'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scan_direction'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['data_storage_order'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scanner_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['x_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['t_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['num_x_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_y_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_z_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_t_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['x_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_acc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_acc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_acc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_motor_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_motor_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_motor_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_encoder_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_encoder_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_encoder_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['date_processed'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 8))\n",
    "    h['time_processed'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 8))\n",
    "    h['depth_recon'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_max_travel'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_max_travel'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['elevation_offset_angle'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['roll_offset_angle'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_max_travel'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['azimuth_offset_angle'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['adc_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['spare06'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scanner_radius'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_offset'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_offset'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_offset'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['t_delay'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['range_gate_start'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['range_gate_end'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['ahis_software_version'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['spare_end'] = np.fromfile(fid, dtype = np.float32, count = 10)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(infile):\n",
    "    \"\"\"Read any of the 4 types of image files, returns a numpy array of the image contents\n",
    "    \"\"\"\n",
    "    extension = os.path.splitext(infile)[1]\n",
    "    h = read_header(infile)\n",
    "    nx = int(h['num_x_pts'])\n",
    "    ny = int(h['num_y_pts'])\n",
    "    nt = int(h['num_t_pts'])\n",
    "    fid = open(infile, 'rb')\n",
    "    fid.seek(512) #skip header\n",
    "    if extension == '.aps' or extension == '.a3daps':\n",
    "        if(h['word_type']==7): #float32\n",
    "            data = np.fromfile(fid, dtype = np.float32, count = nx * ny * nt)\n",
    "        elif(h['word_type']==4): #uint16\n",
    "            data = np.fromfile(fid, dtype = np.uint16, count = nx * ny * nt)\n",
    "        data = data * h['data_scale_factor'] #scaling factor\n",
    "        data = data.reshape(nx, ny, nt, order='F').copy() #make N-d image\n",
    "    elif extension == '.a3d':\n",
    "        if(h['word_type']==7): #float32\n",
    "            data = np.fromfile(fid, dtype = np.float32, count = nx * ny * nt)\n",
    "        elif(h['word_type']==4): #uint16\n",
    "            data = np.fromfile(fid, dtype = np.uint16, count = nx * ny * nt)\n",
    "        data = data * h['data_scale_factor'] #scaling factor\n",
    "        data = data.reshape(nx, nt, ny, order='F').copy() #make N-d image\n",
    "    elif extension == '.ahi':\n",
    "        data = np.fromfile(fid, dtype = np.float32, count = 2* nx * ny * nt)\n",
    "        data = data.reshape(2, ny, nx, nt, order='F').copy()\n",
    "        real = data[0,:,:,:].copy()\n",
    "        imag = data[1,:,:,:].copy()\n",
    "    fid.close()\n",
    "    if extension != '.ahi':\n",
    "        return data\n",
    "    else:\n",
    "        return real, imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bulk_read_data(image_paths):\n",
    "    data = []\n",
    "    for path in image_paths:\n",
    "        path = \"./images/\" + path + \".aps\"\n",
    "        data.append(read_data(path))\n",
    "    return np.stack(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(data, labels, mode):\n",
    "    data = tf.reshape(data, [-1, 512, 660, 16])\n",
    "    print(data.shape)\n",
    "    conv = tf.layers.conv2d(\n",
    "        inputs=data,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    print (conv)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv, pool_size=[2, 2], strides=2)\n",
    "    print(pool1)\n",
    "    flat_pool = tf.reshape(pool1, [-1, 2703360])\n",
    "    print (flat_pool)\n",
    "    logits = tf.layers.dense(inputs=flat_pool, units=17)\n",
    "    print(logits)\n",
    "    #onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=17, name=\"onehot_labels\")\n",
    "    #print(onehot_labels)\n",
    "    print(\"LABELS\" + str(labels))\n",
    "    #test_labels = np.reshape(np.array(labels[\"Probability\"].tolist()), [-1,17])\n",
    "    #test_labels = tf.identity(test_labels, name=\"labels\")\n",
    "    test_labels=tf.identity(labels, name=\"labels\")\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=test_labels, logits=logits)\n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(\n",
    "          input=logits, axis=1, name=\"classes\"),\n",
    "      \"probabilities\": tf.nn.softmax(\n",
    "          logits, name=\"softmax_tensor\")}\n",
    "    print(predictions)\n",
    "    print (tf.contrib.framework.get_global_step())\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.contrib.framework.get_global_step(),\n",
    "        learning_rate=0.001,\n",
    "        optimizer=\"SGD\")\n",
    "    return tf.contrib.learn.ModelFnOps(mode=mode, predictions=predictions, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def input_images():\n",
    "    # labels = genfromtxt('stage1_labels.csv', delimiter=',')\n",
    "    labels = pd.read_csv('stage1_labels.csv')\n",
    "    labels['Id'] = labels['Id'].str.split(\"_\", expand=True)[0].str.strip()\n",
    "    i = tf.contrib.framework.get_global_step()\n",
    "    i = 0 if not i else i\n",
    "    #test_ids = labels['Id'].unique()[((i) * TEST_SIZE):((i + 1) * TEST_SIZE)]\n",
    "    test_ids = labels['Id'].unique()[:100]\n",
    "    data = bulk_read_data(test_ids)\n",
    "    #image_data = tf.convert_to_tensor(data)\n",
    "    return data\n",
    "    # plt.imshow(pooled[1][:,:,18])\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_labels():\n",
    "    # labels = genfromtxt('stage1_labels.csv', delimiter=',')\n",
    "    labels = pd.read_csv('stage1_labels.csv')\n",
    "    i = tf.contrib.framework.get_global_step()\n",
    "    i = 0 if not i else i\n",
    "    labels['Id'] = labels['Id'].str.split(\"_\", expand=True)[0].str.strip()\n",
    "    #test_ids = labels['Id'].unique()[((i) * TEST_SIZE):((i + 1) * TEST_SIZE)]\n",
    "    test_ids = labels['Id'].unique()[:100]\n",
    "    test_labels = labels[labels['Id'].isin(test_ids)]\n",
    "    test_labels = np.reshape(np.array(test_labels[\"Probability\"].tolist()), [-1,17])\n",
    "    return test_labels\n",
    "    # plt.imshow(pooled[1][:,:,18])\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-9f5df2c7784a>:1: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.initialize_all_variables())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0b627a3320>, '_master': '', '_num_ps_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000}\n"
     ]
    }
   ],
   "source": [
    "tsa_classifier = tf.contrib.learn.Estimator(model_fn=build_model, model_dir=\"/tmp/tsa_model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\", \"classes\":\"classes\", \"actual\":\"labels\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-3929011cfc13>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-13-3929011cfc13>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-13-3929011cfc13>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "(?, 512, 660, 16)\n",
      "Tensor(\"conv2d/Relu:0\", shape=(?, 512, 660, 32), dtype=float32)\n",
      "Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 256, 330, 32), dtype=float32)\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 2703360), dtype=float32)\n",
      "Tensor(\"dense/BiasAdd:0\", shape=(?, 17), dtype=float32)\n",
      "LABELSTensor(\"output:0\", shape=(?, 17), dtype=int64)\n",
      "{'classes': <tf.Tensor 'classes:0' shape=(?,) dtype=int64>, 'probabilities': <tf.Tensor 'softmax_tensor:0' shape=(?, 17) dtype=float32>}\n",
      "Tensor(\"global_step/read:0\", shape=(), dtype=int64)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:247: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  equality = a == b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2 into /tmp/tsa_model2/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.24954, step = 2\n",
      "INFO:tensorflow:probabilities = [[ 0.05882042  0.05881017  0.05881716  0.05885525  0.05881666  0.05886224\n",
      "   0.05882987  0.05882478  0.05881279  0.05882199  0.05883227  0.05881472\n",
      "   0.05881866  0.05882357  0.058821    0.05880619  0.05881225]\n",
      " [ 0.05882499  0.05881402  0.05882049  0.05885381  0.05882392  0.05885857\n",
      "   0.05883332  0.05882062  0.05881117  0.05881939  0.0588311   0.05881261\n",
      "   0.0588154   0.05882078  0.05882127  0.05880194  0.05881663]\n",
      " [ 0.05882457  0.05881085  0.05881714  0.05885515  0.0588199   0.05885498\n",
      "   0.05883641  0.05881778  0.05881668  0.05882317  0.05883266  0.05881064\n",
      "   0.05881716  0.05882179  0.05882391  0.05880671  0.05881049]\n",
      " [ 0.05882041  0.05881444  0.0588156   0.05884982  0.05881567  0.05886004\n",
      "   0.05883501  0.05882507  0.05881057  0.05881616  0.05883122  0.05881127\n",
      "   0.05881771  0.0588298   0.05882246  0.05880603  0.05881869]\n",
      " [ 0.05882144  0.05881171  0.05881274  0.05885235  0.0588137   0.05885425\n",
      "   0.05883743  0.05882463  0.05881614  0.05882259  0.05883067  0.05880941\n",
      "   0.0588181   0.05882558  0.05882512  0.05880574  0.05881844]\n",
      " [ 0.05882311  0.05881276  0.05881951  0.058854    0.05882262  0.05886169\n",
      "   0.05884176  0.0588173   0.05881187  0.05881782  0.05882796  0.05880949\n",
      "   0.05881109  0.05882376  0.0588226   0.05880721  0.05881546]\n",
      " [ 0.05882145  0.05881378  0.05882001  0.05885779  0.05882756  0.05885552\n",
      "   0.05883663  0.05881787  0.05881127  0.05881827  0.05882987  0.05880816\n",
      "   0.05881309  0.05882167  0.05882397  0.05880659  0.05881651]\n",
      " [ 0.05882023  0.05881507  0.05881875  0.05885381  0.05881301  0.05885601\n",
      "   0.05883611  0.05882056  0.05881082  0.05881983  0.05883007  0.0588108\n",
      "   0.05881855  0.05882704  0.05882138  0.0588061   0.05882188]\n",
      " [ 0.05882286  0.0588152   0.05881805  0.0588526   0.05882106  0.0588556\n",
      "   0.05883415  0.05882236  0.05881887  0.05882288  0.05882699  0.05880752\n",
      "   0.05881475  0.05882206  0.05882321  0.05880846  0.05881337]\n",
      " [ 0.05882006  0.05881403  0.05881445  0.05884789  0.05881523  0.05885679\n",
      "   0.05883384  0.05882611  0.05881308  0.05882039  0.05883173  0.05881006\n",
      "   0.05881764  0.0588279   0.05882077  0.05880961  0.05882049]], classes = [5 5 3 5 5 5 3 5 5 5], actual = [[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3929011cfc13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtsa_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogging_hook\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0m_call_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             func.__module__, arg_name, date, instructions)\n\u001b[0;32m--> 280\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(\n\u001b[1;32m    282\u001b[0m         func.__doc__, date, instructions)\n",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0m_verify_input_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m       \u001b[0mSKCompat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, steps, max_steps, monitors)\u001b[0m\n\u001b[1;32m   1351\u001b[0m                         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m                         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m                         monitors=all_monitors)\n\u001b[0m\u001b[1;32m   1354\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0m_call_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             func.__module__, arg_name, date, instructions)\n\u001b[0;32m--> 280\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(\n\u001b[1;32m    282\u001b[0m         func.__doc__, date, instructions)\n",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    424\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_session_run_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m       \u001b[0msummary_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSummaryWriterCache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    460\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    784\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    787\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAbortedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         logging.info('An AbortedError was raised. Closing the current session. '\n",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    889\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cody/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tsa_classifier.fit(x=input_images(), y=input_labels(), steps=10000, batch_size=10, monitors=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
