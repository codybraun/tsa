{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import png\n",
    "import tensorflow as tf\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_header(infile):\n",
    "    \"\"\"Read image header (first 512 bytes)\n",
    "    \"\"\"\n",
    "    h = dict()\n",
    "    fid = open(infile, 'r+b')\n",
    "    h['filename'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 20))\n",
    "    h['parent_filename'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 20))\n",
    "    h['comments1'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 80))\n",
    "    h['comments2'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 80))\n",
    "    h['energy_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['config_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['file_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['trans_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scan_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['data_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['date_modified'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 16))\n",
    "    h['frequency'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['mat_velocity'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['num_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_polarization_channels'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['spare00'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['adc_min_voltage'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['adc_max_voltage'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['band_width'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['spare01'] = np.fromfile(fid, dtype = np.int16, count = 5)\n",
    "    h['polarization_type'] = np.fromfile(fid, dtype = np.int16, count = 4)\n",
    "    h['record_header_size'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['word_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['word_precision'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['min_data_value'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['max_data_value'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['avg_data_value'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['data_scale_factor'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['data_units'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['surf_removal'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['edge_weighting'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['x_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['y_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['z_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['t_units'] = np.fromfile(fid, dtype = np.uint16, count = 1)\n",
    "    h['spare02'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['x_return_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_return_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_return_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['scan_orientation'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scan_direction'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['data_storage_order'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scanner_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['x_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['t_inc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['num_x_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_y_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_z_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['num_t_pts'] = np.fromfile(fid, dtype = np.int32, count = 1)\n",
    "    h['x_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_speed'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_acc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_acc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_acc'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_motor_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_motor_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_motor_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_encoder_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_encoder_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_encoder_res'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['date_processed'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 8))\n",
    "    h['time_processed'] = b''.join(np.fromfile(fid, dtype = 'S1', count = 8))\n",
    "    h['depth_recon'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_max_travel'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_max_travel'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['elevation_offset_angle'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['roll_offset_angle'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_max_travel'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['azimuth_offset_angle'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['adc_type'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['spare06'] = np.fromfile(fid, dtype = np.int16, count = 1)\n",
    "    h['scanner_radius'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['x_offset'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['y_offset'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['z_offset'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['t_delay'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['range_gate_start'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['range_gate_end'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['ahis_software_version'] = np.fromfile(fid, dtype = np.float32, count = 1)\n",
    "    h['spare_end'] = np.fromfile(fid, dtype = np.float32, count = 10)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(infile):\n",
    "    \"\"\"Read any of the 4 types of image files, returns a numpy array of the image contents\n",
    "    \"\"\"\n",
    "    extension = os.path.splitext(infile)[1]\n",
    "    h = read_header(infile)\n",
    "    nx = int(h['num_x_pts'])\n",
    "    ny = int(h['num_y_pts'])\n",
    "    nt = int(h['num_t_pts'])\n",
    "    fid = open(infile, 'rb')\n",
    "    fid.seek(512) #skip header\n",
    "    if extension == '.aps' or extension == '.a3daps':\n",
    "        if(h['word_type']==7): #float32\n",
    "            data = np.fromfile(fid, dtype = np.float32, count = nx * ny * nt)\n",
    "        elif(h['word_type']==4): #uint16\n",
    "            data = np.fromfile(fid, dtype = np.uint16, count = nx * ny * nt)\n",
    "        data = data * h['data_scale_factor'] #scaling factor\n",
    "        data = data.reshape(nx, ny, nt, order='F').copy() #make N-d image\n",
    "    elif extension == '.a3d':\n",
    "        if(h['word_type']==7): #float32\n",
    "            data = np.fromfile(fid, dtype = np.float32, count = nx * ny * nt)\n",
    "        elif(h['word_type']==4): #uint16\n",
    "            data = np.fromfile(fid, dtype = np.uint16, count = nx * ny * nt)\n",
    "        data = data * h['data_scale_factor'] #scaling factor\n",
    "        data = data.reshape(nx, nt, ny, order='F').copy() #make N-d image\n",
    "    elif extension == '.ahi':\n",
    "        data = np.fromfile(fid, dtype = np.float32, count = 2* nx * ny * nt)\n",
    "        data = data.reshape(2, ny, nx, nt, order='F').copy()\n",
    "        real = data[0,:,:,:].copy()\n",
    "        imag = data[1,:,:,:].copy()\n",
    "    fid.close()\n",
    "    if extension != '.ahi':\n",
    "        return data\n",
    "    else:\n",
    "        return real, imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bulk_read_data(image_paths):\n",
    "    data = []\n",
    "    for path in image_paths:\n",
    "        path = \"./images/\" + path + \".aps\"\n",
    "        data.append(read_data(path))\n",
    "    return np.stack(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# labels = genfromtxt('stage1_labels.csv', delimiter=',')\n",
    "labels = pd.read_csv('stage1_labels.csv')\n",
    "labels['Id'] = labels['Id'].str.split(\"_\", expand=True)[0].str.strip()\n",
    "test_ids = labels['Id'].unique()[:50]\n",
    "test_labels = labels[labels['Id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "data = bulk_read_data(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_data = tf.convert_to_tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=(50, 512, 660, 16) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-acadc84a6f1c>:10: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "#init = tf.initialize_all_variables()\n",
    "#image_data = tf.convert_to_tensor(image_data)\n",
    "conv = tf.layers.conv2d(\n",
    "    inputs=image_data,\n",
    "    filters=32,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "#sess.run(init)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "#sess.run(tf_filter.eval())\n",
    "#sess.run(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convoluted = sess.run(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convoluted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-caf1552d9127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvoluted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'convoluted' is not defined"
     ]
    }
   ],
   "source": [
    "convoluted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(convoluted[1][:,:,23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool1 = tf.layers.max_pooling2d(inputs=conv, pool_size=[2, 2], strides=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pooled = sess.run(pool1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(pooled[1][:,:,23])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = tf.layers.dense(inputs=pool1, units=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-81459144dee5>:1: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "logited = sess.run(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(logited[0][:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits[0][:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
